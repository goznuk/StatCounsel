---
title: "통계상담 보고서"
author: 
  - 고준혁, 최재훈
format:
  pdf:
    geometry: margin=20mm
    documentclass: article
    latex-engine: xelatex
    mainfont: Malgun Gothic
    monofont: Malgun Gothic Semilight
    fontsize: 10pt
    include-in-header:
      text: |
        \usepackage{fontspec}
date: "2025-03-06"
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
```

해당 보고서는 "장애인 환자의 임플란트 생존율과 영향을 미치는 요인"을 분석하는 실험에서 기존의 분석 방법을 진단하고, 발견된 개선점과 개선 방향을 제시한다. 또한 이를 반영하여 개선한 분석을 수행하고 그 결과데 대한 해석을 제공하는 방식으로 구성되어있다. 

분석은 총 세 가지 파트로 구성된다. 먼저 **기존 분석 방법의 한계**를 점검하고, 이를 보완할 수 있는 개선 방향을 간략하게 소개한다. 다음으로는 이러한 **개선 사항들을 반영한 통계적 방법론의 생존분석**을 실시하고, 그 결과를 해석하여 제시한다. 마지막으로는 기존의 전통적인 통계적 접근법과 차별화된 세 가지의 **머신러닝 기법**을 적용하여 임플란트 생존율에 대한 분석을 수행하며, 각 분석 결과에 대한 해석과 통계적 접근법과 머신러닝 접근법의 요인 분석석을 비교하여 결론을 도출한다.

통계적 방법의 경우, R을 사용하여 분석을 진행하였고 머신러닝 방법의 경우 Python을 사용하여 분석하였다. 또한 각 결과를 확장된 데이터를 가지고 재현할 수 있도록, 분석에 사용한 사용자 정의 함수에 대한 자세한 설명 및 사용 방법을 함께 제공한다. 보다 자세한 코드는 보고서와 함께 제공되는 qmd 형식의 파일을 참고한다.

# 기존 분석 방법의 진단 및 개선 방향

## 1. 데이터 소개

다음 표는 본 분석에서 사용한 Survival_Analysis_consult.sav 파일의 주요 변수를 요약한 것이다. 각 변수는 환자 정보를 비롯하여 임플란트 수술 및 추적 결과 등을 포함한다. 소수의 결측치가 존재하므로 분석 전처리 과정에서 결측치가 있는 데이터행을 삭제하였다. 데이터의 총 길이는 544개이다.

|영문 컬럼|한글 컬럼|설명|
|:-------|:------|:---------|
|patient_ID            |환자 ID                 |환자 고유 식별번호                 |
|me                    |식별 변수(불필요)       |추가 식별 정보                     |
|survival              |생존 여부               |임플란트 생존(1) / 실패(0)         |
|failure_reason        |실패 사유               |임플란트가 실패한 원인             |
|failure_date          |실패일                  |실패 발생 날짜                     |
|last_fu_date          |최종 추적일             |마지막 추적일                      |
|surgery_Date          |수술일                  |임플란트 수술 날짜                 |
|fu_for_fail_yr        |실패 추적기간(년)       |실패한 환자의 추적 기간            |
|fu_for_survival_yr    |생존 추적기간(년)       |생존 환자의 추적 기간              |
|fu_total_yr           |총 추적기간(년)         |모든 환자 대상 총 추적 기간        |
|Sex                   |성별                    |남/녀                              |
|Age                   |나이                    |수술 당시 나이                     |
|type_of_disability_Group2 |장애 유형 그룹2      |환자의 장애 유형을 2차 분류        |
|compliance_with_SPT   |SPT 준수 여부           |유지치료(SPT) 준수(1)/비준수(0)    |
|Systemic_disease      |전신질환 유무/유형      |전신질환 여부                      |
|bone_augmentation_procedure|골증강술 여부      |골증강술 시행(1)/미시행(0)         |
|tooth_loss_reason     |치아상실 원인           |치아상실의 주된 원인               |
|implant_diameter_group|임플란트 직경 그룹      |임플란트 직경을 범주화한 그룹      |
|implant_length_group  |임플란트 길이 그룹      |임플란트 길이를 범주화한 그룹      |
|implant_site          |임플란트 식립 부위      |상악, 하악 내 구체적 위치 구분      |
|jaw                   |턱(상악/하악)           |임플란트가 식립된 턱 위치          |
|prosthesis_type       |보철 유형               |임플란트 상부 보철 형태            |
|periodontal_diagnosis_group|치주 진단 그룹     |치주 상태에 따른 그룹 분류         |


## 2. 기존 연구에 대한 진단

기존 분석에서의 생존분석 방법과 요인 분석에는 몇 가지 개선할 점이 있다. 

- 우선 생존분석에서 가장 기초적인 Kaplan-Meier(KM) estimator(생존함수 추정)를 활용하고 있지 않다. 요인 분석이라는 목적에서 비추어봤을 때, **요인별 생존 곡선**과 **log-rank test**를 추가적으로 적용하면 각 요인이 생존율에 미치는 영향을 보다 직관적으로 시각화할 수 있다. 또한 이는 요인 분석을 위한 변수 선택 및 주요 변수 탐색 전, 변수들에 대한 인사이트를 얻을 수 있는 탐색적 자료분석(EDA)의 일환으로 활용할 수 있다.

- 기존의 요인 분석에서는 **변수 간의 교호작용을 충분히 고려하지 않은 점**이 문제로 지적할 수 있다. 구체적으로, 각 변수에 대한 유의성을 살피고 주요 변수들을 식별한 뒤 식별한 유효 변수들을 모두 포함하는 모델을 적합하게 되면, 모델 적합 과정에서 변수 간의 교호작용으로 인해 회귀 계수가 왜곡될 수 있다. 따라서, 기존 분석과 같이 각 변수를 모델에 적합하여 유의 변수를 식별하는 방법은 지양해야한다.

- 또한 주요 요인 식별 과정에서 **p-value를 사용하는 것**은 바람직하지 않다. p-value의 경우, 회귀 모델의 계수의 유의성을 보이는 지표이며 이는 설명 변수 자체의 유효성을 대변하지 않는다.

- 이를 해결하기 위해 **적절한 모델 평가 지표(AIC, BIC 등)를 활용한 변수 선택 절차를 활용하는 것**이 바람직하다. 예를 들어 모든 변수를 넣은 전체 모형(Full model)에서 출발하여 중요하지 않은 변수를 하나씩 제거하는 **backward elimination**이나, 반대로 최소한의 모형(reduced model)에서 시작해 변수를 추가해 나가는 **forward selection**과 같은 방법을 통해 보다 최적의 변수 조합을 찾는 것을 권장한다. 변수의 수가 현재 실험 데이터와 같이 적은 경우에는 **exhaustive search**와 같은 전역 최적 모델을 구하는 것도 가능할 것이다.

- 연속형 변수와 이산형 변수를 회귀에 함께 사용하는 경우 가변수를 사용한 이산형 변수에 비해 연속형 변수가 variance 측면에서 불리하다. 따라서, 연속형 변수가 변수 선택과정에서 제외되는 경우가 많다. 이와 같은 상황을 최대한 배제하기 위해, 현재 데이터에서 유일한 연속형 변수인 `Age`의 경우 가변수화나 정규화 변환을 사용할 수 있다. 이는 모형의 해석 용이성과 일반화 성능이 향상에 기여할 것이다.

- 마지막으로 한 사람당 하나의 임플란트만 식립된 것이 아니기에, 같은 개체에 동질성과 다른 개체의 이질성을 반영하는, 즉 여러 개의 임플란트 식립 상황을 반영하는, **Shared Frailty**를 사용하여 분석을 진행하는 것이 바람직할 것이다.

---

# 통계적 방법을 이용한 분석

```{r, include=FALSE}
#install.packages("haven")
#install.packages("survival")
#install.packages("KMsurv")
#install.packages("dplyr")
#install.packages("survMisc")
#install.packages("lmtest")
#install.packages("pec")
#install.packages("doParallel")
#install.packages("foreach")
#install.packages("survminer")
#install.packages("gridExtra")
#install.packages("SurvMetrics")
#install.packages("timeROC")
#install.packages("kableExtra")
#install.packages("tidyverse")
#install.packages("ggfortify")


# 패키지 로드
library(pec)
library(doParallel)
library(survival)
library(KMsurv)
library(lmtest)
library(dplyr)
library(survMisc)
library(haven)
library(foreach)
library(survminer)
library(gridExtra)
library(SurvMetrics)
library(timeROC)
library(kableExtra)
library(tidyverse)
library(ggfortify)
```

```{r, echo=FALSE}
raw_data <- read_sav("1. Survival_Analysis_consult.sav") %>%
  mutate(across(where(haven::is.labelled), ~as.numeric(as.factor(.))))

# 설명변수
covariates <- c(
  "Sex",
  "Age_group",
  "type_of_disability_Group2",
  "compliance_with_SPT",
  "Systemic_disease",
  "bone_augmentation_procedure",
  "tooth_loss_reason",
  "implant_diameter_group",
  "implant_length_group",
  "implant_site",
  "jaw",
  "prosthesis_type",
  "periodontal_diagnosis_group"
)
```

## 1. 분석에 사용한 사용자 정의 함수 기능 및 사용방법 
```{r, echo=FALSE}
# 결측값 확인 함수 정의
check_missing <- function(data, covariates, delete = FALSE) {
  
  # 결측값 개수 확인
  missing_counts <- data %>%
    select(all_of(covariates)) %>%
    summarise_all(~ sum(is.na(.))) %>%
    t() %>%
    as.data.frame()
  
  colnames(missing_counts) <- "missing_count"
  missing_counts$variable <- rownames(missing_counts)
  rownames(missing_counts) <- NULL
  
  # delete = TRUE일 경우 결측값이 있는 행 삭제
  if (delete) {
    data <- data %>% filter(if_all(all_of(covariates), ~ !is.na(.)))
    message(nrow(data), " rows remaining after deletion.")
    return(data)
  } else {
    return(missing_counts)
  }
}

# 생존곡선 도사 함수
plot_survival_analysis <- function(data, time_var, event_var, covariate = NULL, alpha = 0.05, ylim = c(0, 1)) {

  # 생존 객체 명시적 정의
  data$time_var_internal <- data[[time_var]]
  data$event_var_internal <- data[[event_var]]
  surv_obj <- Surv(time = data$time_var_internal, event = data$event_var_internal)

  if (is.null(covariate)) {
    fit <- survfit(Surv(time = data$time_var_internal, event = data$event_var_internal) ~ 1, data = data, conf.type = "plain")

    p <- ggsurvplot(
      fit,
      data = data,
      conf.int = TRUE,
      conf.int.fill = "lightblue",
      ylim = ylim,
      ggtheme = theme_minimal(),
      title = "Kaplan-Meier Estimate with 95% CI",
      xlab = "Time",
      ylab = "Survival Probability S(t)",
      legend = "none"
    )

    print(p)

  } else {
    significant_vars <- list()

    # 유의한 공변량 탐색
    for (var in covariate) {
      groups <- as.factor(data[[var]])
      logrank_test <- survdiff(surv_obj ~ groups)
      p_value <- 1 - pchisq(logrank_test$chisq, length(logrank_test$n) - 1)

      if (p_value < alpha) {
        significant_vars[[var]] <- p_value
      }
    }

    if (length(significant_vars) == 0) {
      cat("\n유의한 변수가 없습니다. (alpha =", alpha, ")\n")
      return(NULL)
    }

    num_vars <- length(significant_vars)
    layout_rows <- ceiling(sqrt(num_vars))
    layout_cols <- ceiling(num_vars / layout_rows)

    plot_list <- list()

    # 유의한 각 변수에 대해 KM 곡선 그리기
    for (var in names(significant_vars)) {
      data$group_var_internal <- as.factor(data[[var]])
      fit <- survfit(Surv(time_var_internal, event_var_internal) ~ group_var_internal, data = data)

      p <- ggsurvplot(
        fit,
        data = data,
        risk.table = FALSE,
        conf.int = FALSE,
        palette = "Dark2",
        ylim = ylim,
        ggtheme = theme_minimal(),
        title = paste0(var, " (p=", signif(significant_vars[[var]], 3), ")"),
        xlab = "Time",
        ylab = "Survival Probability S(t)",
        legend.title = var,
        legend.labs = levels(data$group_var_internal)
      )

      plot_list[[var]] <- p$plot
    }

    # 여러 그래프를 하나로 배치
    grid.arrange(grobs = plot_list, nrow = layout_rows, ncol = layout_cols)
  }
}

# global_search를 통한 best model seletion 함수
global_search_cox_cv <- function(data, time_var, event_var, covariates, frailty = NULL, 
                                 cv_folds = 5, time_points = seq(1, 10, by = 1), seed = 1234) {
  set.seed(seed)
  
  covar_combinations <- unlist(lapply(1:length(covariates), function(x) combn(covariates, x, simplify = FALSE)), recursive = FALSE)
  
  cl <- makeCluster(detectCores() - 1)
  registerDoParallel(cl)
  
  results <- foreach(covars = covar_combinations, .combine = rbind, .packages = c("survival", "caret", "dplyr", "timeROC")) %dopar% {
    tryCatch({
      covar_formula <- if (length(covars) > 0) paste(covars, collapse = " + ") else "1"
      
      frailty_term <- if (!is.null(frailty)) paste0(" + frailty(", frailty, ")") else ""
      
      formula <- as.formula(paste0(
        "Surv(", time_var, ", ", event_var, ") ~ ", covar_formula, frailty_term
      ))
      
      # AIC, BIC (전체 데이터)
      full_model <- coxph(formula, data = data, x = TRUE)
      AIC_value <- AIC(full_model)
      BIC_value <- BIC(full_model)
      
      # C-index, AUC (CV로 계산)
      c_index_values <- c()
      auc_values <- c()
      
      folds <- createFolds(data[[event_var]], k = cv_folds, list = TRUE)
      
      for (fold_idx in seq_along(folds)) {
        train_data <- data[-folds[[fold_idx]], ]
        test_data <- data[folds[[fold_idx]], ]
        
        cv_model <- coxph(formula, data = train_data, x = TRUE)
        
        # C-index
        pred_risk <- predict(cv_model, newdata = test_data, type = "lp")
        surv_obj_test <- Surv(test_data[[time_var]], test_data[[event_var]])
        c_index <- survConcordance(surv_obj_test ~ pred_risk)$concordance
        c_index_values <- c(c_index_values, c_index)
        
        # AUC 계산
        auc_result <- tryCatch({
          roc_curve <- timeROC(
            T = test_data[[time_var]],                    
            delta = test_data[[event_var]],              
            marker = pred_risk,              
            cause = 1,                        
            times = time_points,              
            iid = TRUE                        
          )
          mean(roc_curve$AUC, na.rm = TRUE)
        }, error = function(e) NA)
        
        auc_values <- c(auc_values, auc_result)
      }
      
      data.frame(
        ㅡodel = paste(covars, collapse = " + "),
        AIC = AIC_value,
        BIC = BIC_value,
        C_index = mean(c_index_values, na.rm = TRUE),
        AUC = mean(auc_values, na.rm = TRUE)
      )
      
    }, error = function(e) {
      NULL
    })
  }
  
  stopCluster(cl)
  
  if (nrow(results) == 0) {
    cat("\n모든 조합에서 에러가 발생하여 결과가 없습니다.\n")
    return(NULL)
  }

  # best 모델들 정보와 성능 지표 출력
  best_models <- bind_rows(
    results %>% slice(which.min(AIC)) %>% mutate(Criterion = "AIC"),
    results %>% slice(which.min(BIC)) %>% mutate(Criterion = "BIC"),
    results %>% slice(which.max(C_index)) %>% mutate(Criterion = "C_index"),
    results %>% slice(which.max(AUC)) %>% mutate(Criterion = "AUC")  # AUC 기반 모델 추가
  ) %>%
    select(Criterion, Ｍodel, AIC, BIC, C_index, AUC)

  return(best_models)
}

# Cox-Snell residual을 이용한 모델 진단 함수
cox_snell_diagnosis <- function(data, time_var, event_var, covariates) {
  
  # Cox 모델 적합
  formula <- as.formula(paste0("Surv(", time_var, ", ", event_var, ") ~ ", paste(covariates, collapse = "+")))
  cox_model <- coxph(formula, data = data, x = TRUE)
  
  # Cox-Snell 잔차 계산
  cox_snell_residuals <- residuals(cox_model, type = "martingale")
  cs_residuals <- -(cox_snell_residuals - 1)
  
  # Cox-Snell 잔차를 이용한 생존 객체 생성
  surv_obj <- Surv(cs_residuals, event = data[[event_var]])
  
  # Kaplan-Meier 추정
  km_fit <- survfit(surv_obj ~ 1)
  
  # 누적위험함수 계산
  cum_hazard <- -log(km_fit$surv)
  
  # 데이터 프레임 생성
  df <- data.frame(
    time = km_fit$time,
    cum_hazard = cum_hazard
  )
  
  # ggplot으로 그래프 그리기
  plot <- ggplot(df, aes(x = time, y = cum_hazard)) +
    geom_step(color = "steelblue", linewidth = 1.2) +
    geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed", linewidth = 1) +
    labs(
      title = "Cox-Snell Residuals Model Diagnosis",
      x = "Cox-Snell Residuals",
      y = "Cumulative Hazard"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
      axis.title = element_text(size = 14)
    )
  
  return(print(plot))
}
```

### 1.1 `check_missing()`

**기능**: 특정 변수들(`covariates`)에서 결측치(NA) 개수를 확인하고 제거하는 함수이다. `delete=TRUE`를 설정하면 해당 결측이 포함된 행을 모두 제거한 데이터를 반환한다. 이외의 경우 결측치의 갯수만 반환한다.

**매개변수**:

- `data`: 분석할 데이터
- `covariates`: 결측치 확인 대상 변수 목록 (결측치가 없어야하는 설명 변수)
- `delete`: 결측이 포함된 행을 제거할지 여부 (기본값: `FALSE`)

**주의**: 결측치가 많으면 유효 표본 수가 줄어들 수 있으며, `delete=TRUE`로 인해 데이터 손실이 있을 수 있으므로 결측치의 갯수를 확인하고 데이터 제거 여부를 결정하는 것이 필요하다.

**사용방법**:
```{r, eval=FALSE}
# 결측 개수 확인
check_missing(raw_data, covariates)  
# 결측치가 포함된 행 제거한 데이터 반환
check_missing(raw_data, covariates, delete=TRUE)  
```

### 1.2 `plot_survival_analysis()`

**기능**: **Kaplan-Meier 생존곡선**을 그리며, 특정 변수별 생존곡선 비교를 수행할 수 있는 함수이다. 특정 변수별 생존곡선 비교를 실행하는 경우, Log-rank test를 진행하여 해당 검정에서 유의한 변수들의 검정 결과와 생존곡선만을 보여준다. KM 생존곡선을 통해 시간이 지남에 따른 생존율 변화를 직관적으로 파악할 수 있고, Log-rank 검정을 통해 두 그룹 이상 간 생존함수 차이가 통계적으로 유의한지 확인할 수 있다. \([1]\)

**매개변수**:

- `data`: 분석할 데이터
- `time_var`: 생존 시간 변수
- `event_var`: 사건 발생 여부 변수
- `covariate`: 비교할 그룹 변수들 (기본값: `NULL` / 벡터로 여러 covariate에 대한 결과출력 가능)
- `alpha`: 유의수준 (기본값: `0.05`)
- `ylim`: y축(생존률) 범위 (기본값: `c(0,1)`)

**사용방법**:
```{r, eval=FALSE}
# 전체 생존곡선
plot_survival_analysis(data, "fu_total_yr", "survival")
# 변수별 생존곡선
plot_survival_analysis(data, "fu_total_yr", "survival", covariate = "Age_group")  
```


### 1.3 `global_search_cox_cv()`

**기능**: Cox 회귀분석을 수행하며, 다양한 변수 조합을 탐색하여 최적 모델을 선정한다. 모델 선택은

(1)**AIC** (2)**BIC** (3) **C-index** (4) **time-dependent AUC** 

의 네가지 평가지표를 기준으로 진행한다. 각 기준에서 최적의 성능을 보이는 모델을 식별하며 결과는 각 최적 모델에 대한 지표값을 요약한 표로 반환한다. AIC와 BIC의 경우, 모델이 가지는 제공 데이터에 대한 설명력의 측면에서, 나머지 두 가지 지표의 경우는 모델의 예측력 측면에서 모델을 평가하는 지표이다.

**매개변수**:

- `data`: 분석할 데이터
- `time_var`: 생존 시간 변수
- `event_var`: 사건 발생 여부 변수
- `covariates`: 고려할 설명변수 목록
- `frailty`: 공유 프레일티 모형 적용 여부 (기본값: `NULL`) / 적용하는 경우, 해당 변수명 입력
- `cv_folds`: 교차검증 폴드 수 (기본값: `5`)
- `time_points`: 시간 종속 AUC를 계산할 시점 벡터 (기본값: `seq(1,10, by=1)`), 즉, AUC가 계산될 시점들을 입력
- `seed`: 난수 시드 설정 (기본값: `1234`)

**사용방법**:
```{r, eval=FALSE}
result <- global_search_cox_cv(data, "fu_total_yr", "survival", covariates)
result_frailty <- global_search_cox_cv(data, "fu_total_yr", "survival", 
                                       covariates, frailty="patient_ID")
```

### 1.4 `cox_snell_diagnosis()`

**기능**:  Cox 회귀모델에 대해 Cox-Snell 잔차를 계산하고, 이 잔차를 기반으로 누적위험함수를 추정함으로써 모델 적합도를 진단한다. 잔차의 누적위험함수를 그래프로 표시했을 때, y = x 직선에 가깝게 분포하면 모델이 자료를 적절히 설명하고 있음을 시사한다. 분석 데이터가 Cox 모델을 적합하는게 적절한지 진단하는 방법으로 해당 분석에서는 사용하였다. 

**매개변수**:

- `data`: 분석할 데이터
- `time_var`: 생존 시간 변수
- `event_var`: 사건 발생 여부 변수
- `covariates`: Cox 모델에 포함할 변수 목록

**사용방법**:
```{r, eval=FALSE}
diagnosis <- cox_snell_diagnosis(data, "fu_total_yr", "survival", covariates)
```


## 2. 데이터 전처리

1.**나이변수 범주화**
```{r}
raw_data <- raw_data %>%
  mutate(Age_group = factor(case_when(
    Age < 40 ~ "Under 40",
    Age >= 40 & Age < 60 ~ "40-59",
    Age >= 60 ~ "60 and over"
  ), levels = c("Under 40", "40-59", "60 and over")))
```

기존 분석의 개선 사항을 반영하여 연령을 연속형 대신 세 구간(40세 미만, 40-59세, 60세 이상)의 이산형 변수로 변환하였다. 이는 임상적으로 유의한 연령 구간을 설정하고, 나이에 따른 그룹 간 생존율 차이를 간편히 비교하기 위함이다. 또한, Cox regression을 사용한 변수 선택에서 데이터 형태를 통일하여 bias를 막기 위함도 있다.

2. **결측치 처리**: 

`check_missing()` 함수를 통해 주요 설명변수(`covariates`)에 결측치가 있는 행을 제거하였다. 이는 분석 대상을 결측 없는 완전 사례로 한정하기 위함이며, 결측치의 양이 많을 경우 다른 방법(대치법 등)을 고려할 수 있다. 현재의 분석 데이터에서는 결측치가 있는 사례가 한 가지이기에 제거하는 방법을 택했다.

```{r, echo=FALSE}
data = check_missing(raw_data, covariates, delete = T)
```

3. **불필요한 변수 제거**:

```{r}
data <- data %>%
  select(-c("me", "Age", "failure_reason", "failure_date", 
            "last_fu_date", "surgery_Date", "fu_for_fail_yr",
            "fu_for_survival_yr"))
```

분석 목적과 직접 관련 없는 변수(예: `me`, `failure_reason` 등)를 제거하여 최종 분석용 데이터(`data`)를 구성하였다.

## 3. 모델 평가지표 및 분석방법 설명

### 3.1 분석방법 개요

#### 3.1.1 생존함수와 검열(Censoring)

- **생존시간** $T$는 확률변수이며 어떤 사건(예: 사망, 재발 등)까지 걸리는 시간을 의미한다.

- **생존함수**:
$$
S(t) = P(T > t),
$$
즉 시점 $t$ 까지 사건이 발생하지 않고 생존해 있을 확률이다.

- **위험함수(Hazard function)**:
$$
h(t) = \lim_{\delta t \to 0} \frac{P(t \le T < t + \delta t \mid T \ge t)}{\delta t} 
= \frac{f(t)}{S(t)},
$$
여기서 $f(t)$는 생존시간의 확률밀도함수이다.

- **검열(censoring)**이란 관측 종료 시점까지 사건 발생이 관측되지 않은 경우(오른쪽 검열) 등을 말한다. 이러한 검열된 데이터까지 고려하여 분석해야 한다는 점에서, 일반적인 회귀분석 등의 통계적 접근과는는 다른 접근이 필요하다.

#### 3.1.2 Kaplan-Meier 추정 (KM 추정)

- 사건 발생 시점들을 $t_{(1)} < t_{(2)} < \cdots < t_{(r)}$ 라 하고, 해당 시점에서 사건이 발생하는 관측수를 $d_j$, 해당 시점 직전에 위험집단에 속한 수를 $n_j$ 라 할 때,
$$
\hat{S}(t) = \prod_{t_{(j)} \le t} \left( 1 - \frac{d_j}{n_j} \right).
$$
- 위와 같이 KM 추정을 통해 시간에 따른 생존확률 구한 것을 KM 추정량이라 하고 이를 시각화한 **생존곡선**(Kaplan-Meier curve)을 얻을 수 있다. 생존곡선을 통해 시간 경과에 따른 사건 발생 패턴을 직관적으로 파악할 수 있다 \([1]\).

#### 3.1.3 Log-rank test

- **두 그룹 이상**의 생존함수를 비교하기 위해 사용되는 검정이다.
- 각 사건 발생 시점에서 그룹별 위험집단(사건이 아직 발생하지 않은 표본) 크기를 바탕으로 관측된 사건 수와 기대 사건 수를 비교하여 검정 통계량을 구한다.
- (예시) : 두 그룹(A, B)이 있다고 할 때, 어떤 시점 $t_j$ 에서
  - 그룹 A에서 사건 발생: $d_{j,A}$, 위험집단: $n_{j,A}$
  - 그룹 B에서 사건 발생: $d_{j,B}$, 위험집단: $n_{j,B}$
  - 전체 사건 수: $d_j = d_{j,A} + d_{j,B}$, 전체 위험집단: $n_j = n_{j,A} + n_{j,B}$
  - 그룹 A에서 기대 사건 수: $\frac{n_{j,A} \times d_j}{n_j}$
- 이러한 방식으로 전체 사건 시점을 합산하여 카이제곱(chi-square) 검정 통계량을 계산하고, **생존곡선의 차이가 통계적으로 유의한지** 확인할 수 있다.

#### 3.1.4 Cox 회귀분석 (Cox proportional hazards model, coxph)

- 생존시간에 영향을 미치는 여러 독립변수(공변량)를 고려하기 위한 반(半)모수적(semi-parametric) 모형이다.
- **비례위험가정(Proportional Hazards Assumption)** : 공변량 변화가 "위험함수 $h(t)$"에 승수적인(배수) 영향을 미치며, 시간에 따라 위험비(Hazard Ratio)가 일정하다는 가정.
- 모형 식:
$$
h(t \mid X) = h_0(t) \exp(\beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_p X_p),
$$
  - $h_0(t)$: **기준위험함수(baseline hazard)** (비모수적으로 추정)
  - $\beta_i$: 추정해야 할 회귀계수
- **부분가능도(Partial Likelihood)**를 통해 $\beta$ 를 추정한다. 전체 파라미터(기준위험함수 포함)를 모두 추정하지 않고, 사건 발생 순서 정보로부터 $\beta$ 만을 추정하게 된다.

#### 3.1.5 Cox-Snell 진단
- **모델 적합도(goodness-of-fit)를 평가**하기 위해 사용하는 잔차(residual) 분석 기법 \([7, \text{p.81–83}]\).
- Cox-Snell 잔차 $r_i$ 는 각 관측치 $i$의 누적위험함수(estimated cumulative hazard) 값을 이용하여 정의할 수 있다:
$$
r_i = \hat{H}(T_i) = -\log(\hat{S}(T_i))
$$

- 만약 모델이 데이터를 잘 설명한다면, $r_i$들은 (이론적으로) 평균이 1인 지수분포를 따르게 되며, 누적 위험함수 그래프에서 $y = x$ 직선 부근에 점들이 고루 분포한다. 따라서 검정 결과에서 그린 누적 위험함수가 얼마나 $y = x$ 에 잘 근사하는 지를 통해 모델 적합도를 진단할 수 있다.

#### 3.1.6 Shared Frailty 모형

- **Shared frailty** 모형은 생존분석에서 집단(clusters) 내의 관측치 간 상관성을 고려하기 위한 확장 모형이다. 해당 분석에서는 동일 환자에 식립 사례에 대한 동질성과 다른 환자들의 사례와의 이질성을 반영하기 위해 사용하였다. 
- **Shared frailty**를 고려한 생존시간 $T_{ij}$ (관측치 $j$가 그룹 $i$에 속한 경우)에 대한 위험함수는 다음과 같다.
$$
h_{ij}(t|\alpha_i) = h_0(t)\alpha_i \exp(\mathbf{X}_{ij}'\boldsymbol{\beta})
$$

- $\alpha_i$: 그룹(클러스터) 별 frailty 효과, 해당 분석에서는 환자별별
- 그룹 내 개체들은 동일한 $\alpha_i$ 값을 공유하며, 그룹 간 이질성을 설명할 수 있다 \([2]\).

### 3.2 모델 평가지표

#### 3.2.1 AIC (Akaike Information Criterion)
$$
\text{AIC} = -2 \times \log L + 2k,
$$

- $\log L$: 모델의 최대가능도값,
- $k$: 추정해야 할 모수(파라미터) 수

모델의 가능도 값과 복잡성을 모두 고려한 모델 평가지표이며, 값이 작을수록 자료에 잘 적합된 모델로 볼 수 있다.

#### 3.2.2 BIC (Bayesian Information Criterion)
$$
\text{BIC} = -2 \times \log L + k \log(n),
$$

- $n$: 표본 크기

AIC와 유사하나, 표본 크기를 고려하여 복잡한 모델에 대해 더 강한 패널티를 부과하는 평가지표이다. AIC, BIC는 “모델이 주어진 자료를 얼마나 잘 설명하는가”라는 **추론(inference)** 혹은 **설명력** 관점에서 중요하다.

#### 3.2.3 C-index (Concordance Index)

- 생존분석에서 예측된 위험도(risk score) 순위와 실제 사건 발생 순서의 일치도를 나타내는 지표.
- Cox 모형 등에서 **예측 성능을 평가**하기 위한 핵심 지표로 활용하며, 자세한 설명은 머신러닝 방법을 이용한 분석 파트의 4.1을 참고하길 바란다. 

#### 3.2.4 Cumulative AUC (Cumulative Area Under the Curve)

- **ROC 곡선**(민감도 vs. 1-특이도) 아래 면적으로, 예측력이 높을수록 1에 가까워진다.
- 생존분석에서는 **시간 의존(time-dependent) AUC**를 고려할 수 있으며, 특정 시점 $t$에서 사건 발생 여부 예측을 평가한다 \([4]\). 0.5에서 1.0의 범위를 갖는다. 이 또한 자세한 설명은 머신러닝 방법을 이용한 분석 파트의 4.3을 참고하길 바란다.

#### 3.2.5 교차검증(Cross Validation, CV)

- 데이터를 여러 개 폴드(fold)로 나눈 뒤, 한 폴드를 검증용(Validation)으로, 나머지를 학습용(Training)으로 사용한다. 또한 이를 폴드 개수만큼 반복한다.
- 예측 성능 지표(C-index, AUC 등)에 대해 각 폴드에서 계산한 값을 평균해 모델의 최종 성능을 추정한다.
- **과적합(Overfitting)** 문제를 방지하고 **모델의 일반화 성능**을 더 공정하게 평가할 수 있다 \([5]\).

### 3.3 모델 선택 전략

- **AIC, BIC**는 자료 적합도(모델 설명력)와 복잡도(변수 수)를 함께 고려하므로, “현상 설명”이나 “추론” 목적일 때 주로 사용 \([6]\).
- **C-index, AUC**는 “새로운 데이터(또는 검증 세트)에 대한 예측 정확도”를 반영하는 지표로, “예측” 목적일 때 더 중점적으로 고려.
- **교차검증**을 통해 (C-index, AUC 등) 예측 성능을 추정하여, 여러 후보 모형을 비교한다.
- 종합적으로 AIC/BIC (추론 관점)과 C-index/AUC (예측 관점)를 모두 검토하여 최적 모델을 선택한다.

## 4. 분석 결과 및 해석
### 4.1 Kaplan-Meier Analysis

해당 부분에서는 KM-estimator를 통해서 생존함수와 생존곡선을 추정하고, 임플란트 생존율의 특성이 어떠하며 어떤 요인들에 따라 생존율에 차이가 있는지를 Log-rank test를 통해 확인한다.

#### 4.1.1 생존함수 추정(KM-estimator) 및 생존곡선
```{r, fig.width=8, fig.height=5, out.width='60%', fig.align='center', echo=FALSE}
plot_survival_analysis(
  data = data,
  time_var = "fu_total_yr",
  event_var = "survival",
  ylim = c(0.8, 1)
)
```

- 다음은 KM 추정법을 사용하여 전체 데이터에 대한 생존 확률을 추정한 그래프이다. x축은 시간(년)이며 y축은 생존 확률이다. 
- 데이터에서 제공하는 최장기간의 follow-up period를 고려하더라도 추정 생존 확률이 0.9를 상회하는 것을 확인할 수 있다. 따라서, 전체적으로 임플란트의 장기 생존율이 높다고 볼 수 있다. 
- 구체적인 해석으로는 8년에서 10년 사이 다소 급격한 추정 생존율 하락하는 것을 통해 해당 기간에 임플란트 탈락 가능성이 가장 높다고 추론할 수 있다.

#### 4.1.2 각 요인별(설명변수별) Log-rank test 및 생존곡선
```{r, echo=FALSE, out.width='75%', fig.align='center'}
plot_survival_analysis(
  data = data,
  time_var = "fu_total_yr",
  event_var = "survival",
  covariate = covariates,
  ylim = c(0.7, 1)
)
```

- 해당 결과는 각 설명 변수별 level에 따른 생존곡선의 차이를 검정하는 Log-rank test를 진행하고 이에 따른 유의 변수들의 검정 결과와 생존 곡선을 나타낸다. 
- **장애 유형과 식립 위치, 보철 유형**에 따른 생존율의 차이가 유의하다는 결과를 확인할 수 있다. 이는 각 변수들의 level에 따른 생존 곡선을 통해서도 확인할 수 있다.
- 특히, 보철 유형의 경우, **3유형**에서 생존율이 떨어지는 결과를 확인할 수 있다.

### 4.2 요인 분석을 위한 Cox regression (모델 선택)

#### 4.2.1 Shared Frailty를 고려하지 않은 모델
```{r, echo=FALSE}
#result <- global_search_cox_cv(data, time_var = "fu_total_yr", 
#                               event_var = "survival", covariates = covariates)
result <- read.csv("no_frailty_result.csv")

result %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%
  kbl(booktabs = TRUE, caption = "Model Selection Results - without Shared Frailty") %>%
  column_spec(2, width = "8cm") %>% # 2번째 컬럼(모델 설명 컬럼) 폭 조정
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```

- 임플란트 탈락에 영향을 주는 요인 분석을 위해 Shared Frailty를 고려하지 않은 모델의 변수 선택을 진행하였으며 위와 같은 변수 선택 결과를 확인할 수 있다. 

- 데이터의 설명력 측면에서 해석 가능한 AIC, BIC 기준의 식별 모델의 경우, 앞서 진행한 Log-rank test에서 유의 변수로 식별한 **장애 유형**과 **식립 위치**를 공통적으로 유의한 변수로 선택하였다. 또한 AIC, BIC 기준 식별 모델 모두에서 **치아 상실 원인**을 임플란트 탈락에 영향을 주는 요인으로 선택하였다. 이외 AIC 기준 식별 모델에서 **연령층, 보철 유형, 치주 상태** 등을 유의 변수로 선택하였다.

- 예측에 주안점을 둔 AUC를 기준으로 모델을 식별한 경우, 설명력에 주안점을 둔 모델들과는 다르게 새로운 변수들이 추가되거나 제거되는 것을 확인할 수 있다. 다만 절대적인 AUC의 수치를 보았을 때, 0.5와 1사이에 값을 가지는 평가지표임에도 불구하고 상당히 작은 값인 0.65를 가지는 모습을 확인할 수 있다. 따라서,  예측력의 측면에서 강점을 가지는 모델이라고 보기 어렵다. 또한 몇몇 후보 모델의 경우에는 데이터 수의 제한으로 인해 AUC가 계산되지 않기도 한다. 따라서 이렇게 식별한 변수들이 임플란트 탈락을 예측하는데 유의한 변수라고 하기는 어렵다.

- C-index를 기준으로 변수를 선택한 경우에는 AUC와는 다르게 0.77의 유의미한 평가 지표를 통해 변수를 식별하였다. 앞서 진행한 Log-rank test의 **장애 유형, 식립 위치, 보철 유형**이 모두 예측에 영향을 주는 주요 요인으로 식별되었고, 이외 **치아 상실 원인, 전신 질환 유무, 치주 진단 그룹**등의 변수가 예측 측면에서 유의 변수로 식별됨을 확인할 수 있다.

#### 4.2.2 Shared Frailty를 고려한 모델
```{r, echo=FALSE}
#result_frailty <- global_search_cox_cv(data, time_var = "fu_total_yr", event_var = "survival", 
#                                       covariates = covariates, frailty = "patient_ID")
result_frailty <- read.csv("frailty_result.csv")

result_frailty %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%
  kbl(booktabs = TRUE, caption = "Model Selection Results - with Shared Frailty") %>%
  column_spec(2, width = "8cm") %>% # 2번째 컬럼(모델 설명 컬럼) 폭 조정
  kable_styling(latex_options = c("striped"), full_width = FALSE, position = "center")
```

- 한 환자에게 다수의 식립 사례가 있는 경우를 반영하기 위해 Shared Frailty를 고려한 모델의 변수 선택을 진행하였으며, 위와 같은 변수 선택 결과를 확인할 수 있다. 전반적으로 변수가 Shared Frailty를 고려하지 않은 모델들에 비해 많은 변수들이 선택되는 것을 확인할 수 있다.

- 앞선 결과와 마찬가지로 AIC, BIC 기준 식별 모델의 경우 **장애 유형**과 **식립 위치**, **치아 상실 원인**가 공통적으로 유의한 변수로 선택하였으며 추가적으로 **연령층, SPT 준수 여부, 전신 질환, 치주 상태** 변수가 유의 변수로 공통적으로 선택하였다. 이외 **임플란트 직경**의 경우, BIC 기준 모델에서 유의 변수로 선택하였음을 확인할 수 있다.

- 예측에 목적을 둔 모델 AUC를 평가지표로 식별한 유의변수들의 경우, 앞선 Shared Frailty를 고려하지 않은 결과와 동일하게 AUC의 값이 0.68로 유의하지 않게 나와 해당 평가지표를 사용하여 식별한 모델은 예측력의 측면에서 강점을 가지는 모델이라고 보기 어렵다. 따라서 이렇게 선택한 변수가 임플란트 탈락을 예측하는데 영향을 주는 변수라고 할 수 없다.

- C-index를 기준으로 변수를 선택한 경우에는  0.81의 유의미한 평가 지표를 통해 변수를 식별하였다. 앞서 진행한 Log-rank test의 **장애 유형, 식립 위치, 보철 유형**이 모두 예측에 영향을 주는 주요 요인으로 식별되었고, 이외 **치아 상실 원인, 임플란트 길이, 치주 진단 그룹**등의 변수가 예측 측면에서 유의 변수로 식별됨을 확인할 수 있다.

## 5. 기타 이슈
### 5.1 데이터 부족 및 특성에 따른 제한
```{r, fig.width=8, fig.height=5, out.width='60%', fig.align='center', echo=FALSE}
# 예시: AIC 기준 최적 모델 선택
best_model_vars <- strsplit(result$model[1], " \\+ ")[[1]]

# cox_snell_diagnosis 실행
diagnosis <- cox_snell_diagnosis(
  data = data,
  time_var = "fu_total_yr",
  event_var = "survival",
  covariates = best_model_vars
)
```

- 앞선 분석 결과를 통해 예측에 목적을 둔 평가지표를 통한 요인 분석이 제대로 작동하지 않음을 확인할 수 있다. 이에 대한 원인 분석을 위해 모델의 적합도를 평가하는 Cox-Snell diagnosis를 진행하였다.  

- 현재 대부분의 식별 모델에서는 위와 같은 형태의 추정 누적 위험함수를 확인할 수 있다. 이는 **데이터 자체의 부족** 및 **데이터 내 실패 사례들이 부족한 특성**으로 인한 현상이라고 볼 수 있다. 임플란트 탈락 사례 자체가 흔치 않은 크게 right censored된 데이터라고 할 수 있으며, 이와 같은 데이터 특성으로 인해 time-dependent한  AUC의 특정 시점의 값이 계산되지 않는 것과 같은 오류가 발생하여 위와 같은 오류가 발생했다. 이와 같은 원인은 실패 사례가 충분한 데이터를 보충함으로써 일정 부분 해결할 수 있을 것이나 데이터 자체의 특성인 실패 사례 부족이 해소되는 것이 아니기에 다음 평가지표를 사용한 요인 분석은 지양하길 권한다.

---

# 머신러닝 방법을 이용한 분석

## 1. Random Survival Forest (RSF)

### 1.1 개요

Random Survival Forest(RSF)는 기존의 랜덤 포레스트(Random Forest)를 생존분석에 적용한 방법이다. 랜덤 포레스트가 다수의 의사결정나무(Decision Tree)를 앙상블하여 예측 성능을 높이는 방식과 유사하게, RSF는 생존 데이터에서 여러 개의 생존 나무(Survival Tree)를 훈련하고 이들의 결과를 종합하여 예측한다.

### 1.2 특징

- **비모수적(non-parametric) 방법**: 특정한 분포 가정을 필요로 하지 않으며, 데이터의 구조를 유연하게 반영할 수 있다.
- **검열 데이터(censored data) 처리**: 일반적인 회귀 및 분류 모델과 달리 생존시간 데이터에서 검열(censoring)된 값을 효과적으로 처리할 수 있다.
- **생존 확률 및 누적위험 계산**: 개별 노드에서 누적위험률(cumulative hazard rate)과 생존 확률(survival rate)을 계산하여 예측을 수행한다.

## 2. DeepSurv \([9]\)

### 2.1 개요

**DeepSurv**는 신경망(Neural Network, NN) 기반의 생존분석 모델로, Cox 비례위험 모형(Cox Proportional Hazard Model, CoxPH)을 확장한 형태이다. 딥러닝 기법을 적용하여 복잡한 변수 간의 관계를 학습하고, 개인별 생존 리스크를 예측할 수 있도록 설계되었다.
비례위험 가정 $h(t|X) = h_0(t) \cdot \exp(r(X))$에서 $r(X)$를 추정하는 과정에서 **DeepSurv**라는 딥러닝 기법을 적용했다.

### 2.2 모델 세부 설명

```{r, echo=FALSE, fig.align='center', out.width="40%"}
knitr::include_graphics('deepsurv.jpeg')
```


DeepSurv 모델의 다이어그램은 위와 같다. 기본적인 딥러닝의 feed-forward deep neural network의 구조를 가진다. 모델의 output $\hat{h}_{\theta}(x)$는 모델을 통해 예측된 log-risk function이다.
학습에 사용되는 loss function, 즉 $\hat{\theta}$를 추정 과정에서 최소화하는 함수는 다음과 같다.

$$
l(\theta) := -\frac{1}{N_{E=1}} \sum_{i: E_i=1} \left( \hat{h}_\theta(x_i) - \log \sum_{j \in \mathcal{R}(T_i)} e^{\hat{h}_\theta(x_j)} \right) + \lambda \cdot \|\theta\|_2^2,
\text{where } \mathcal{R}(t) = \{ i : T_i > t \}
$$

위 loss function은 CoxPH와 다른 형태를 띠고 있다. CoxPH의 loss function은 다음과 같다.
$$
L_c(\beta) = \prod_{i: E_i=1} \frac{\hat{r}_\beta(x_i)}{\sum_{j \in \mathcal{R}(T_i)} \hat{r}_\beta(x_j)}
= \prod_{i: E_i=1} \frac{\exp(\hat{h}_\beta(x_i))}{\sum_{j \in \mathcal{R}(T_i)} \exp(\hat{h}_\beta(x_j))},
$$
Loss function을 최소화하는 $\hat{\theta}$를 찾는 과정은 여러 방법이 있지만, 이 논문과 우리의 연구에서는 **Adaptive Moment Estimation (Adam) for the gradient descent algorithm**을 이용했다.

### 2.3. Treatment recommender system (치료 추천 시스템) : CoxPH와 비교했을 때의 장점
DeepSurv 참고문헌\([9]\)에서 DeepSurv가 CoxPH에 대해 가질 수 있는 장점으로 **치료 추천 시스템**을 설명하고 있다.

임상 연구에서 환자는 개별적인 예후 요인과 받는 치료에 따라 서로 다른 위험 수준을 갖는다. 이를 일반화하여 모든 환자를 $n$개의 치료 그룹 중 하나에 할당한다고 가정한다. 각 치료 $i$에 대해 독립적인 위험 함수 $e^{h_i(x)}$를 설정하면, 전체 위험 함수는 다음과 같이 표현된다.
$$ \lambda(t; x|\tau = i) = \lambda_0(t) \cdot e^{h_i(x)} $$

#### 치료 추천 함수

환자의 특정 치료 $i$에 대한 log-risk function $h_i(x)$를 정확히 예측하는 것이 중요하다. 각 환자가 동일한 기본 위험 함수 $\lambda_0(t)$를 갖는다고 가정하면, 위험비(Hazard Ratio)의 로그 값을 활용하여 특정 치료 옵션에 대한 개인별 위험비를 계산할 수 있다. 이를 **추천 함수(recommender function)**라고 하며, 다음과 같이 정의한다.

$$
 \text{rec}_{ij}(x) = \log \left(\frac{\lambda(t; x|\tau = i)}{\lambda(t; x|\tau = j)}\right) = h_i(x) - h_j(x)
$$
즉, 특정 치료 $i$와 치료 $j$ 간의 위험도를 비교하는 값이다.

#### 추천 함수의 활용

- 환자를 모델에 한 번 입력하여 치료 그룹 $i$에 대한 결과를 얻고, 다시 치료 그룹 $j$에 대한 결과를 얻은 후 두 값을 비교한다.
- 만약 **추천 함수 값이 양수**이면, 치료 $i$가 치료 $j$보다 사망 위험이 높음을 의미하므로, 환자에게 치료 $j$를 추천해야 한다.
- 반대로 **추천 함수 값이 음수**이면, 치료 $i$가 더 효과적이며, 사망 위험이 치료 $j$보다 낮음을 의미하므로 치료 $i$를 권장한다.

#### DeepSurv의 장점

- DeepSurv는 **사전에 치료 상호작용 항을 정의하지 않고** 자동으로 추천 함수를 계산할 수 있는 반면, CoxPH 모델에서는 **치료 상호작용 항이 포함되지 않으면 추천 함수가 일정한 값으로 유지**된다.
- 치료 간의 상호작용을 발견하는 것은 의학적 지식이 필요하므로, DeepSurv는 CoxPH보다 치료 추천 측면에서 효율적이다.

## 3. TabNet \([11]\)

### 3.1. 개요  
TabNet은 **2021년 개발된 테이블형 데이터(tabular data) 특화 딥러닝 모델**이다. 기존의 딥러닝 신경망 모델은 음성, 이미지 등 **비정형 데이터** 분석에서 뛰어난 성능을 보였으나, **정형 데이터** 분석에서는 두드러진 성능 향상이 나타나지 않았다. 이에 따라, **테이블형 데이터 분석에 적합한 딥러닝 모델**로서 TabNet이 개발되었다. 기존의 트리 기반 방법과 달리, **순차적 주의(attention) 메커니즘을 활용하여 학습 과정에서 중요한 변수를 선택**한다.  

### 3.2. 특징

- DeepSurv와 유사하게, 생존 분석(survival analysis)에서 **비례위험 가정을 적용하여 위험 함수를 추정**하는 방식으로 활용할 수 있다. \([12])\ 

- RSF 및 DeepSurv와 달리, **TabNet은 생존 분석 분야에서 널리 사용된 모델이 아니며**, 최근 관련 연구들이 점차 등장하고 있다.  

## 4. 모델의 설명 가능성 (Explainability) 분석

위에 기술한 **RSF, DeepSurv**는 **머신러닝, 딥러닝 방법을 사용하므로 전통적인 CoxPH보다 모델 해석이 어렵다**. 따라서 머신러닝 모델의 결과 해석에 도움이 되는 **Feature Importance 기법**을 적용하였다. 참고 논문 \([10]\)에서는 두 가지 주요 설명 가능성 분석 기법을 활용하였다.

### **4.1 Permutation Feature Importance**

- 대표적인 변수 중요도 평가법 중 하나로, **원본 데이터와 특정 변수를 랜덤하게 섞은 데이터의 모델 성능 차이를 비교하여 변수의 중요도를 측정**한다.
- 중요한 변수일수록 변형된 데이터에서 모델 성능이 크게 감소하며, 이를 통해 변수별 영향도를 확인할 수 있다.
- 다중공선성에 취약하다는 단점이 있다.

### **4.2 SHAP (SHapley Additive exPlanations)**
- 최근에도 많이 연구가 되고 있는 방법 중 하나이다.
* 변수 간의 모든 가능한 상호작용을 고려하여 특정 변수의 기여도를 계산할 수 있다.
* 모델이 특정 결과를 도출한 이유를 설명하는 데 활용할 수 있으며, 특히 DeepSurv 등 비선형 모델에서 해석력을 높이는 데 유용하다.

## **5. 모델 평가 지표**

참고 논문\([10]\)에서는 모델 성능을 평가 지표로서 **Concordance-Index (C-Index), Integrated Brier Score (IBS), Cumulative AUC (Area Under the Curve)**를 활용하였다.

### **5.1 Concordance Index (C-Index, 순위 일관성 지수)**

$$
C = \frac{\sum_{i,j} I(T_i < T_j) I(\hat{r}_i > \hat{r}_j)}{\sum_{i,j} I(T_i < T_j)}
$$

  C-Index는 **예측된 위험도(risk score)와 실제 생존 시간의 일관성을 측정하는 지표**이다. 두 개의 비교 가능한 샘플 $(i, j)$에 대해, 실제로 **생존 시간이 짧은 샘플이 더 높은 위험도 ** $\hat{r}$ **를 갖는 경우**, 해당 예측이 올바른 것으로 간주한다. $C = 1$이면 모델이 완벽하게 예측한 것이며, $C = 0.5$는 무작위 예측과 동일한 수준을 의미한다.


### **5.2 Integrated Brier Score (IBS, 통합 Brier 점수)**

$$
IBS = \int_0^{t_{\max}} \frac{1}{N} \sum_{i=1}^{N} (S(t | X_i) - Y_i(t))^2 dt
$$

 
Brier Score는 특정 시간 $t$에서 **실제 생존 여부**와 **예측된 생존 확률** 간의 평균 제곱 오차(Mean Squared Error, MSE)를 측정하는 지표이다. censoring(중도 절단) 데이터가 있는 생존 분석에 적합한 지표이며, 특정 시점이 아닌 여러 시점에 걸쳐 측정된 값을 통합하여 시간 전반에 걸친 예측 오류를 평가한다. **0에 가까울수록 모델의 예측 정확도가 높음**을 의미한다.

### **5.3 Cumulative Area Under the Curve (Cumulative AUC, 누적 AUC)**

$$
AUC(t) = P(\hat{r}_i > \hat{r}_j | T_i \leq t, T_j > t)
$$

  누적 AUC는 특정 시간 $t$까지 이벤트(사건)가 발생한 개체와 아직 생존한 개체 간의 위험도(risk score) 차이를 비교하는 지표이다. 참고 논문\([10]\)에서는 $AUC(t)$ 대신 시간에 따른 $AUC(t)$의 평균치인 **mean AUC**를 지표로 활용하였다.

## **6. 모델 학습 절차 \([10]\)**

### **6.1 전처리**
머신러닝 방법 적용 전, 범주형 변수들을 **One-hot encoding**을 통해 모델 학습에 적합한 형태로 변환했다.

- **One-hot encoding:**  
  범주형 변수를 여러 개의 **이진(0/1) 변수**로 변환하는 방식  
  예) `"A", "B", "C"` → `[1,0,0]`, `[0,1,0]`, `[0,0,1]`


### **6.2 하이퍼파라미터 최적화**

각 모델의 최적 성능을 찾기 위해 **하이퍼파라미터 최적화**를 수행하였다. 본 분석에서는 Python의 **Optuna** 라이브러리를 사용하여 하이퍼파라미터 탐색을 진행하였다.

**Optuna 최적화 과정:**

1. 미리 정의된 하이퍼파라미터 범위에서 **무작위로 값을 선택(trial)**  
2. 선택된 하이퍼파라미터를 사용하여 모델을 학습하고 성능을 평가  
3. **50번의 trial을 반복**한 후,  
   **Concordance Index(C-Index)가 가장 높은 하이퍼파라미터**를 최종 모델에 적용  

Optuna의 설정값은 **`config.yaml`** 파일에서 정의되어 있으며, 각 모델별 적절한 하이퍼파라미터의 범위를 설정하여 탐색하였다. 참고 논문\([10]\)에서는 **5-fold cross validation**을 통해 구한 C-Index를 이용하였다. 최적의 하이퍼파라미터를 찾은 후, 이를 이용하여 모델을 학습한 후 **C-Index, IBS, mean AUC**를 기반으로 성능을 비교하였다. 위 모든 모델 학습 과정을 다음과 같이 시각화할 수 있다.
```{r, echo=FALSE, fig.align='center', out.width="80%"}
knitr::include_graphics('figure_learning.png')
```

### **6.3 Feature Importance 분석**

각 머신러닝 모델의 **Permutation Feature Importance**와 **SHAP 값(Shapley Additive Explanations, SHAP value)**을 활용하여 변수 중요도를 분석한다. **Permutation Feature Importance**는 테이블 형태로 제시하여 각 변수의 상대적 중요도를 수치적으로 확인하고, **SHAP 값**은 **beeswarm plot**을 사용하여 모델이 특정 예측을 수행하는 과정에서 개별 변수가 미치는 영향을 시각적으로 분석한다. 모델별 최종 학습 결과 중 5-fold cross-validation의 테스트 성능이 가장 우수한 fold의 결과를 선택하여 분석을 진행한다.

## **7. RSF 학습 결과**

### **7.1 RSF 최적 하이퍼파라미터 값**

|`n_estimators`|`min_samples_leaf`|`max_features`|`max_depth`|
|:-------------|:-----------------|:-------------|:----------|
|508           |5                 |14            |14         |

### **7.2 5-fold Cross Validation 성능 결과**

```{r, echo=FALSE, show_col_types = FALSE}

results <- tibble(
  Fold = c(0, 1, 2, 3, 4),
  C_Index = c(0.5951, 0.7051, 0.6112, 0.7808, 0.9135),
  Mean_AUC = c(NA, 0.7196, 0.6664, 0.8383, 0.9445),
  IBS = c(0.0665, 0.0255, 0.0503, 0.0398, 0.0398)
)

results %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%
  kbl(booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)

```

각 폴드(fold)에서 평가된 **C-Index, Mean AUC, IBS**는 위와 같다.  
5개의 fold의 결과를 평균 내어 최종 RSF 모델의 scores를 계산했다. `fold 0`에서 `Mean_AUC`는 결측치로 계산되었고, 해당 경우에는 평균 계산에서 제외하였다.

**모델 최종 scores**

```{r, echo=FALSE, message=FALSE}
library(kableExtra)

# 모델 최종 scores 데이터 생성
final_scores <- data.frame(
  Metric = c("C-index", "Mean AUC", "IBS"),
  Score = c(0.721135, 0.792195, 0.044387)
)
# kable을 사용하여 캡션 포함한 표 생성
final_scores %>%
  kbl(booktabs = TRUE, caption = "Final Model Scores for RSF") %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```




### **7.3 Feature Importance**

#### **7.3.1 Permutation Feature Importance**

```{r, echo=FALSE, show_col_types = FALSE}
RSF_permutation_importances_fold_4 <- read.csv("RSF_permutation_importances_fold_4.csv")

RSF_permutation_importances_fold_4 %>%
  rename(X = 1) %>% 
  mutate_if(is.numeric, round, 5) %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%
  kbl(booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```

**7.2**의 결과를 이용해 **fold 4**의 변수 중요도를 분석했다. `X`는 변수명, `importances_mean`, `importances_std`는 각각 15번 계산한 permutation feature importance의 평균과 표준편차이다. `implant_site_p`, `prosthesis_type_single`, `tooth_loss_reason_perio` 순으로 변수 중요도가 높게 측정되었다. 변수 중요도가 0에 가깝거나, 음수가 나오는 변수들도 여럿 존재함을 확인할 수 있다.

#### **7.3.2 SHAP values**

```{r, echo=FALSE, fig.align='center', out.width="70%"}
knitr::include_graphics('RSF_beeswarm_fold_4.png')
```

그래프의 점들은 data point를 의미한다. 변수 중요도가 큰 변수의 이름을 내림차순으로 정렬한 것이 y축에 해당한다. x축 `SHAP value`는 데이터의 해당 변수가 예측값에 미친 영향을 의미한다. 0 이상이면 예측값 증가에 기여, 0 이하이면 예측값 감소에 기여했다는 의미이다. 점의 색깔은 해당 데이터의 변수값이 전체 데이터에서 얼마나 큰 편인지를 나타낸다. 우리의 상황은 범주형 변수 뿐이고, one-hot encoding을 통해 0, 1로 변환했으므로, 붉은 색 점은 해당 데이터가 변수명에 있는 범주에 속함을 의미한다. 예를 들어, `prothesis_type_single` 변수의 붉은 점은 해당 데이터의 `prothesis_type`가 `single`임을 의미하고, 파란 점은 `prothesis_type`가 `single`이 아님을 의미한다.  (`bridge`, `overdenture`) Permutation Feature Importance와 비슷하게 `prothesis_type`, `implant_site`, `tooth_loss_reason` 등이 주요 변수로 뽑혔다.

RSF 모델에선 범주형 변수의 값에 따라 예측값의 영향이 명확하다는 것을 그래프를 통해서도 확인할 수 있다. `prothesis_type`이 `single`일 경우 위험도를 높게 예측한다. `implant_site`가 `a`인 관측치들은 risk를 높이는 쪽으로 영향을 줬고, `p`인 관측치들은 risk를 낮추는 쪽으로 영향을 줬다.   Tree-based 모델 특성상 범주형 변수의 값에 따라 예측값이 달라지는 경향이 있는데, SHAP value의 그래프에서도 확인할 수 있다.




## **8. DeepSurv 학습 결과**

### **8.1 DeepSurv 최적 하이퍼파라미터 값**

|`batch_size`|`inner_dim`|`lr`|`weight_decay`|
|:-----------|:----------|:---|:-------------|
|1024        |64         |$10^{-5}$|0.01     |

  `config.yaml`에 제시된 `batch_size`는 512, 1024, 1770, 3540이다. 현 데이터의 개수는 약 540개이므로 유의미한 `batch_size`를 찾기는 어렵다. `batch_size`를 바꿔서 학습한 결과, 심한 오버피팅이 관측되어 기존 `batch_size`를 이용하였다.

### **8.2 5-fold Cross Validation 성능 결과 & Final Score**

```{r, echo=FALSE, show_col_types = FALSE}
results <- data.frame(
  Fold = c(0, 1, 2, 3, 4),
  C_Index = c(0.5913, 0.5530, 0.4528, 0.6141, 0.3984),
  Mean_AUC = c(NA, 0.5255, 0.3549, 0.5401, 0.4221),
  IBS = c(0.1035, 0.0314, 0.0632, 0.0596, 0.0653)
)

results %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%
  kbl(booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```

```{r, echo=FALSE, message=FALSE}
library(kableExtra)

# 모델 최종 scores 데이터 생성
final_scores <- data.frame(
  Metric = c("C-index", "Mean AUC", "IBS"),
  Score = c(0.521925, 0.460670, 0.064590)
)
# kable을 사용하여 캡션 포함한 표 생성
final_scores %>%
  kbl(booktabs = TRUE, caption = "Final Model Scores for DeepSurv") %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```


### **8.3 Feature Importance**

#### **8.3.1 Permutation Feature Importance**

```{r, echo=FALSE, message=FALSE}
DeepSurv_permutation_importances_fold_3 <- read_csv("DeepSurv_permutation_importances_fold_3.csv", show_col_types=FALSE)

DeepSurv_permutation_importances_fold_3 %>%
  rename(X = 1) %>% 
  head(5) %>% 
  mutate_if(is.numeric, round, 5) %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%
  kbl(booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```

**8.2**의 결과를 이용해 **fold 3**의 변수 중요도를 분석했다. `jaw_mx`, `Sex_M`, `type_of_disability_Group2_Non-Mental` 순으로 변수 중요도가 높게 측정되었다.

#### **8.3.2 SHAP values**

```{r, echo=FALSE, fig.align='center', out.width="70%"}
knitr::include_graphics('DeepSurv_beeswarm_fold_3.png')
```

  DeepSurv 모델에서는 RSF에서 Permutation Feature Importance가 낮았던 `jaw_mx` 변수가 SHAP 값에서 높은 중요도를 보였다. 분석 결과, `jaw`가 `mx`일 때 risk가 증가하는 경향을 나타냈다. 또한, `implant_diameter` 변수의 경우 `regular` 그룹에 속할 때 위험도가 낮아졌으며, `wide` 그룹에서도 유사한 경향을 보였다. `periodontal_diagnosis_group` 변수는 `stage 3,4`일 때 오히려 위험도가 감소하는 패턴을 보였으며, `type_of_disability` 변수는 `Non-Mental` 그룹에 속할 때 위험도가 높게 나타났다.  

  한편, RSF와 DeepSurv 모델 간 Permutation Feature Importance와 SHAP 값의 중요도 순위 차이가 크게 나타났다.  예를 들어, `Sex` 변수는 Permutation Feature Importance에서 2번째로 중요도가 높았지만, SHAP 분석에서는 6번째에 위치했다. 이처럼 두 지표는 산출 방식이 다르므로, 변수의 중요도 순위가 달라질 수 있다.
  
## **9. TabNet 학습 결과**

### **9.1. TabNet 최적 하이퍼파라미터 값**

|`n_d`|`n_steps`|`gamma`|`lr`|`weight_decay`|`mask_type`|
|:----|:--------|:------|:---|:-------------|:----------|
|25   |8        |1.7    |0.001|1            |`entmax`   | 

```{r, echo=FALSE, show_col_types = FALSE}
results <- data.frame(
  Fold = c(0, 1, 2, 3, 4),
  C_Index = c(0.5913, 0.5530, 0.4528, 0.6141, 0.3984),
  Mean_AUC = c(NA, 0.5255, 0.3549, 0.5401, 0.4221),
  IBS = c(0.1035, 0.0314, 0.0632, 0.0596, 0.0653)
)

results %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%
  kbl(booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```

### **9.2 5-fold Cross Validation 성능 결과**

```{r, echo=FALSE, message=FALSE, show_col_types = FALSE}

# TabNet 5-Fold Cross Validation 결과 데이터 생성
results <- data.frame(
  Fold = c(0, 1, 2, 3, 4),
  C_Index = c(0.5501, 0.5207, 0.6770, 0.6232, 0.7807),
  Mean_AUC = c(NA, 0.5479, 0.7701, 0.7506, 0.8289),
  IBS = c(0.0743, 0.0267, 0.0476, 0.0462, 0.0461)
)

# 테이블 정리 및 스타일 적용
results %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%  
  kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```

```{r, echo=FALSE, message=FALSE}
library(kableExtra)

# 모델 최종 scores 데이터 생성
final_scores <- data.frame(
  Metric = c("C-index", "Mean AUC", "IBS"),
  Score = c(0.630357, 0.724382, 0.048174)
)
# kable을 사용하여 캡션 포함한 표 생성
final_scores %>%
  kbl(booktabs = TRUE, caption = "Final Model Scores for TabNet") %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```

### **9.3 Feature Importance**


#### **9.3.1 Permutation Feature Importance**

```{r, echo=FALSE, message=FALSE}
TabNet_permutation_importances_fold_4 <- read_csv("TabNet_permutation_importances_fold_4.csv", show_col_types=FALSE)

TabNet_permutation_importances_fold_4 %>%
  rename(X = 1) %>% 
  head(5) %>% 
  mutate_if(is.numeric, round, 5) %>%
  mutate(across(everything(), ~ifelse(is.na(.), "-", .))) %>%
  kbl(booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), full_width = FALSE)
```

**9.2**의 결과를 이용해 **fold 4**의 변수 중요도를 분석했다. `implant_site`, `bone_augmentation_procedure`, `compliance_with_SPT` 순으로 변수 중요도가 높게 측정되었다.

#### **9.3.2 SHAP values**

```{r, echo=FALSE, fig.align='center', out.width="70%"}
knitr::include_graphics('TabNet_beeswarm_fold_4.png')
```

아래는 SHAP plot 해석을 위한 변수별 값이다.

| **Variable**                   | **Encoded Value** | **Original Category**        |
|--------------------------------|-------------------|------------------------------|
| **Sex**                        | 0                 | F                            |
| **Sex**                        | 1                 | M                            |
| **Age**                        | 0                 | middle-aged                  |
| **Age**                        | 1                 | old                          |
| **Age**                        | 2                 | young                        |
| **type_of_disability_Group2**  | 0                 | Mental                       |
| **type_of_disability_Group2**  | 1                 | Non-Mental                   |
| **compliance_with_SPT**        | 0                 | complete                     |
| **compliance_with_SPT**        | 1                 | erratic                      |
| **compliance_with_SPT**        | 2                 | non                          |
| **Systemic_disease**           | 0                 | n                            |
| **Systemic_disease**           | 1                 | y                            |
| **bone_augmentation_procedure**| 0                 | n                            |
| **bone_augmentation_procedure**| 1                 | y                            |
| **tooth_loss_reason**          | 0                 | non_perio                    |
| **tooth_loss_reason**          | 1                 | perio                        |
| **implant_diameter_group**     | 0                 | narrow: 4<                   |
| **implant_diameter_group**     | 1                 | regular: 4>= & 5<            |
| **implant_diameter_group**     | 2                 | wide: 5>=                    |
| **implant_length_group**       | 0                 | Length < 10                  |
| **implant_length_group**       | 1                 | Length ≥ 10                  |
| **implant_site**               | 0                 | a                            |
| **implant_site**               | 1                 | p                            |
| **jaw**                        | 0                 | md                           |
| **jaw**                        | 1                 | mx                           |
| **prosthesis_type**            | 0                 | bridge                       |
| **prosthesis_type**            | 1                 | overdenture                  |
| **prosthesis_type**            | 2                 | single                       |
| **periodontal_diagnosis_group**| 0                 | stage 0,1,2                  |
| **periodontal_diagnosis_group**| 1                 | stage 3,4                    |




## **10. 머신러닝 방법론 유의사항**


### **10.1 충분한 데이터 수 확보**
다수의 머신러닝과 딥러닝 방법론에서는 데이터 수가 중요하다. 모델에 사용되는 파라미터의 수가 매우 많기 때문에, CoxPH처럼 준모수적 방법을 사용할 때 보다 더 많은 데이터가 있어야 모델의 성능이 증가할 수 있다. 또한 생존분석 특성상 fail event에 대한 관측이 제한되어 있기 때문에, 정확한 위험함수를 추정하기 위해서는 실패 사례에 대한 데이터의 양도 충분해야 한다. 데이터의 양이 부족할수록 위험함수 추정에 어려움을 겪을 것을 예상할 수 있다.
또한, DeepSurv와 TabNet의 경우 논문 \( [10] \)의 경우보다 데이터의 수가 많이 부족했다. 논문에 있는 모델 세팅에서는 DeepSurv & TabNet에 대해 최소 512, 1024 정도의 batch size를 요구하고 있다. 이는 우리의 데이터 수를 상회하는 값으로, 같은 상황에서 모델을 학습했을 때 학습이 잘 되지 않는 결과를 보였다. Batch size 조절로 (파이썬 코드 설명 참고) 문제를 해결할 수 있었지만, 많은 양의 데이터가 확보된다면 더욱 일반적인 상황에 대해 모델을 학습시킬 수 있을 것이다.

### **10.2 비례위험 가정**
DeepSurv와 TabNet, CoxPH는 **비례위험 가정(Proportional Hazards Assumption)**을 기반으로 한 생존 분석 모델이다. 반면, **Random Survival Forest(RSF)**는 비례위험 가정을 요구하지 않는다. 따라서, **DeepSurv와 TabNet을 적용하기 전에 비례위험 가정이 충족되는지 검증**하는 과정이 필요하다. 이를 통해 **모델 사용의 타당성을 높이고, 분석 결과의 신뢰성을 확보**할 수 있다.


### **10.3 비례위험 가정에 대한 통계적 검정**

* 비례위험 가정을 검정하는 대표적인 방법 중 하나가 **Schoenfeld 잔차 검정(Schoenfeld Residual Test)**이다.
* 귀무가설 $H_0$ : **비례위험 가정이 성립**한다. vs 대립가설 $H_1$ : **비례위험 가정이 성립하지 않는다.**
* 이 검정에서 사용되는 검정통계량은 카이제곱(Chi-square) 분포를 따르며, p-value가 0.05보다 작을 경우 귀무가설을 기각하고 해당 변수에서 비례위험 가정이 성립하지 않는다고 판단한다.

#### **R에서의 Schoenfeld 잔차 검정 수행 방법**

Schoenfeld 잔차 검정은 R의 `survival` 패키지에서 제공하는 `cox.zph()` 함수를 활용한다. `cox.zph()`는 다변량 CoxPH에 포함된 각 변수에 대해 개별적으로 비례위험 가정이 성립하는지 검정하며, 모델 전체에 대한 비례위험 가정에 대한 검정(GLOBAL 검정)도 함께 수행한다.

```{r}
# 다변량 Cox 회귀 분석 (shared frailty 고려X, AIC 기준, 변수 선택 (4.2.1 참고) )
multivariate_model <- coxph(Surv(fu_total_yr, survival) ~
                              Age_group + type_of_disability_Group2 + tooth_loss_reason + 
                              implant_site + prosthesis_type + periodontal_diagnosis_group,
                              data = data)

# Schoenfeld 잔차 검정 수행
NPH_CHECK <- cox.zph(multivariate_model) 
```

```{r, echo=FALSE}

# 데이터 생성
chisq_results <- data.frame(
  Variable = c("Age_group", "type_of_disability_Group2", "tooth_loss_reason",
               "implant_site", "prosthesis_type", "periodontal_diagnosis_group", "GLOBAL"),
  Chisq = c(6.72, 2.45, 2.45, 3.85, 0.32, 3.42, 18.02),
  df = c(2, 1, 1, 1, 1, 1, 7),
  p_value = c(0.035, 0.118, 0.118, 0.050, 0.571, 0.064, 0.012)
)

# 테이블 출력
kable(chisq_results, caption = "Schoenfeld 잔차 검정 결과")

```

검정을 통해, 다변량 CoxPH에 포함된 각 변수에 대해 개별적으로 비례위험 가정의 성립 여부를 확인했다. `Age_group` 변수에서는 95% 유의수준에서 비례위험 가정이 성립하지 않는 것으로 나타났다. 또한, GLOBAL 행의 p-value가 작게 나타났으며, 이는 모델 전체적으로 비례위험 가정이 성립하지 않는다는 것을 의미한다.

### **10.4 Schoenfeld 잔차 검정 결과의 시각적 해석**

```{r, fig.align='center', echo=FALSE, message=FALSE}

# Schoenfeld 잔차 데이터 추출 및 변환
schoenfeld_residuals <- as.data.frame(NPH_CHECK$y)
schoenfeld_residuals$Time <- NPH_CHECK$x  # 시간 추가
schoenfeld_residuals <- pivot_longer(schoenfeld_residuals, cols = -Time, names_to = "Variable", values_to = "Residual")

# 원하는 변수 순서 정의
variable_order <- c("Age_group", "type_of_disability_Group2", "tooth_loss_reason", 
                    "implant_site", "prosthesis_type", "periodontal_diagnosis_group")

# 변수 순서를 factor로 지정
schoenfeld_residuals$Variable <- factor(schoenfeld_residuals$Variable, levels = variable_order)

# ggplot2 시각화 (직선 추가)
ggplot(schoenfeld_residuals, aes(x = Time, y = Residual)) +
  geom_point(alpha = 0.6) + 
  geom_smooth(method = "loess", se = TRUE, color = "blue", span = 2) + 
  facet_wrap(~ Variable, scales = "free_y") +  # 변수 순서 적용된 facet_wrap
  labs(title = "Schoenfeld Residuals for Proportional Hazards Assumption",
       x = "Time",
       y = "Scaled Schoenfeld Residuals") +
  
  theme_minimal() +
  theme(legend.position = "none")
```

`cox.zph()`을 활용한 그래프로 비례위험 가정에 대한 시각적인 확인도 가능하다. `cox.zph()`을 통해 얻은 그래프는 시간에 따른 계수 $\beta(t)$의 변화를 추정한 결과를 나타낸다.
.
 만약 비례위험 가정이 성립한다면, $\beta(t)$ 값이 시간에 따라 일정해야 하므로 그래프가 수평선을 이루어야 한다. 비례위험 가정을 기각한 `Age_group` 변수의 그래프는 시간이 지남에 따라 우상향하는 패턴을 보였다. 이는 시간이 흐름에 따라 해당 변수의 영향력이 증가한다는 것을 의미하며, 비례위험 가정이 성립하지 않을 가능성이 높음을 시사한다.  
 
 반면, 검정 결과에서는 비례위험 가정이 성립한다고 판정되었음에도 그래프에서 수평선에서 벗어난 형태를 보이는 경우가 있었다. `type_of_disability`와 `implant_site` 변수의 그래프는 시간에 따른 변동이 포물선이나 곡선처럼 복잡한 형태를 보인다. 이는 Schoenfeld 잔차 검정이 선형적인 관계만을 가정하기 때문에, 보다 복잡한 시간 의존적 관계는 검정으로 완전히 파악할 수 없음을 의미한다.  

 따라서, 비례위험 가정 검정의 결과뿐만 아니라 Schoenfeld 잔차 그래프를 함께 분석하여 해석하는 것이 바람직하다.


### **10.5 비례위험 가정 위배 변수에 대한 보정 (시간의존적 효과 추가)**

Schoenfeld 잔차 검정을 활용한 결과, `Age_group`에서 시간이 지남에 따라 **계수 $\beta(t)$ 가 증가**하는 경향을 보였다. 이는 해당 변수들이 시간이 흐름에 따라 위험도에 미치는 영향이 변화한다는 것을 의미한다. 이를 반영하기 위해, $j$번째 변수에 대해 기존 CoxPH 모델을 다음과 같이 수정할 수 있다.

$$
\beta_j(t) = \beta_j + v_j (t - \bar{t})
$$

또는 단순한 형태로

$$
\beta_j(t) = \beta_j \cdot t
$$
와 같이 수정 가능하다.

모델을 적용하면, 시간이 경과함에 따라 특정 독립변수가 위험도에 미치는 영향이 증가하거나 감소하는 패턴을 반영할 수 있다. 예를 들어, $\beta_j > 0$인 경우 $j$번째 변수의 위험 기여도가 시간이 지남에 따라 증가하는 것으로 해석 가능하다.

#### **시간의존적 효과 변수 추가 방법**

시간의존적 효과 변수를 추가하는 방법은 `Surv()` 함수와 `coxph()` 함수의 `tt()` 옵션을 활용하여 구현할 수 있다. 아래 코드는 `Age_group`에 대해 시간의존적 효과를 반영하는 방식으로 CoxPH 모델을 구축한 것이다. 코드에 `tt(variable)` 옵션을 추가하여, 해당 변수와 시간(time) 간의 상호작용을 반영했다.

```{r}
# Step 1: 변수 더미화 (Dummy Variable Transformation)
data <- data %>%
  mutate(
    age_under_40 = ifelse(Age_group == "Under 40", 1, 0),
    age_btw_40_59 = ifelse(Age_group == "40-59", 1, 0)
  )

# Step 2: 시간의존적 효과를 포함한 Cox 모델 적합
cox_model_fixed <- coxph(Surv(fu_total_yr, survival) ~ age_under_40 + age_btw_40_59 + 
                           type_of_disability_Group2 + tooth_loss_reason + 
                           implant_site + prosthesis_type + 
                           periodontal_diagnosis_group + 
                           tt(age_under_40) + tt(age_btw_40_59), 
                         data = data, tt=function(x,t,...) x*t)
```


**결과 및 해석**

시간의존적 효과를 반영한 CoxPH 모델을 적합한 결과, 모형 설명력 관련 지표들이 전부 개선되었다.(아래 표 참고) 이는 비례위험 가정 위배 문제를 해결함과 동시에 모델의 유의성이 강화됐음을 뜻한다. 따라서, 비례위험 가정이 위배된 변수를 포함하는 Cox 모델을 적용할 때는 Schoenfeld 잔차 검정을 수행한 후, 필요한 경우 시간의존적 효과 변수를 추가하여 모델의 타당성을 높이는 것이 바람직하다.

| Metric                        | Fixed Model (Baseline) | Time-Dependent Model |
|--------------------------------|----------------------|----------------------|
| **Concordance Index**          | 0.750 (SE = 0.048)  | 0.789 (SE = 0.039)  |
| **Likelihood Ratio Test**      | 33.15 on 7 df, `p = 2e-05` | 41.71 on 9 df, `p = 4e-06` |
| **Wald Test**                  | 33.04 on 7 df, `p = 3e-05` | 36.23 on 9 df, `p = 4e-05` |
| **Score (Log-rank) Test**      | 37.22 on 7 df, `p = 4e-06` | 43.22 on 9 df, `p = 2e-06` |



아래는 Python의 random seed = 1234 기준 두 모형의 C-Index를 5-fold cross validation을 통해 확인한 결과이다. 위의 결과와는 다르게, 여기서는 시간의존적 효과 변수를 추가하지 않은 것이 예측력을 높일 수 있음을 시사한다. 즉, **설명력에서는 시간의존적 효과 변수 추가, 예측력 측면에서는 기존 모형이 더 좋음을 의미한다.**


```{r,include=FALSE, eval=FALSE, warning = FALSE}

# 1️⃣ Python에서 생성한 데이터 불러오기
train_test_split <- read_csv("train_test_split.csv", show_col_types = FALSE)
kfold_indices <- read_csv("kfold_indices.csv", show_col_types = FALSE)

# 2️⃣ 원본 데이터 불러오기 (데이터셋 이름: data)
data <- data %>%
  mutate(
    age_under_40 = ifelse(Age_group == "Under 40", 1, 0),
    age_btw_40_59 = ifelse(Age_group == "40-59", 1, 0)
  )

# 3️⃣ KFold Cross Validation을 통해 Concordance Index 계산
unique_folds <- sort(unique(kfold_indices$fold))
cindex_results_fixed <- c()
cindex_results_td <- c()

for (fold in unique_folds) {
  # cat("Processing Fold:", fold, "\n")
  
  # Training & Validation 데이터 분할
  train_idx <- kfold_indices$index[kfold_indices$fold != fold]  # Training set
  val_idx   <- kfold_indices$index[kfold_indices$fold == fold]  # Validation set

  train_data <- data[train_idx, ]
  val_data   <- data[val_idx, ]
  
  # 4️⃣ Cox 모델 학습 (고정 변수 모델)
  multivariate_model <- coxph(Surv(fu_total_yr, survival) ~
                                Age_group + type_of_disability_Group2 + tooth_loss_reason + 
                                implant_site + prosthesis_type + periodontal_diagnosis_group, 
                              data = train_data)
  
  # 5️⃣ Cox 모델 학습 (Time-dependent 변수 포함)
  cox_model_fixed <- coxph(Surv(fu_total_yr, survival) ~ 
                                 age_under_40 + age_btw_40_59 + type_of_disability_Group2 + tooth_loss_reason + 
                                 implant_site + prosthesis_type + periodontal_diagnosis_group
                                 + tt(age_under_40) + tt(age_btw_40_59), 
                           data = train_data, tt = function(x, t, ...) x * t)
  
  # 6️⃣ Validation 데이터에서 Concordance Index 계산
  pred_risk <- predict(multivariate_model, newdata = val_data, type = "lp")
  surv_obj_test <- Surv(val_data$fu_total_yr, val_data$survival)
  cindex_fixed <- survConcordance(surv_obj_test ~ pred_risk)$concordance
  


  pred_risk <- predict(cox_model_fixed, newdata = val_data, type = "lp")
  surv_obj_test <- Surv(val_data$fu_total_yr, val_data$survival)
  cindex_td <- survConcordance(surv_obj_test ~ pred_risk)$concordance
  
  
  # 7️⃣ 결과 저장
  cindex_results_fixed <- c(cindex_results_fixed, cindex_fixed)
  cindex_results_td <- c(cindex_results_td, cindex_td)
}

# 8️⃣ 최종 Concordance Index 평균 출력
#cat("Average Concordance Index (Fixed Model):", mean(cindex_results_fixed), "\n")
#cat("Average Concordance Index (Time-Dependent Model):", mean(cindex_results_td), "\n")

```


| Model                        | Average C-index |
|------------------------------|--------------------------|
| Fixed Model                  | 0.7162                   |
| Time-Dependent Model         | 0.6911                   |



---

#### 참고문헌

1. Klein, John P., et al. "Censoring and truncation." Survival analysis: techniques for censored and truncated data (2003): 63-90.

2. Gutierrez, Roberto G. "Parametric frailty and shared frailty survival models." The Stata Journal 2.1 (2002): 22-44.

3. Harrell, Frank E. Regression modeling strategies: with applications to linear models, logistic regression, and survival analysis. Vol. 608. New York: springer, 2001.

4. Hung, Hung, and Chin‐Tsang Chiang. "Estimation methods for time‐dependent AUC models with survival data." Canadian Journal of Statistics 38.1 (2010): 8-26.

5. Clark, Taane G., and Douglas G. Altman. "Developing a prognostic model in the presence of missing data: an ovarian cancer case study." Journal of clinical epidemiology 56.1 (2003): 28-37.

6. Germer, Sebastian, et al. "Survival analysis for lung cancer patients: A comparison of Cox regression and machine learning models." International Journal of Medical Informatics 191 (2024): 105607.

7. Therneau, Terry M., et al. The cox model. Springer New York, 2000.

8. Kleinbaum, David G., and Mitchel Klein. Survival analysis a self-learning text. Springer, 1996.

9. Katzman, Jared L., et al. "DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network." BMC medical research methodology 18 (2018): 1-12. https://doi.org/10.1186/s12874-018-0482-1

10. Germer S, Rudolph C, Labohm L, Katalinic A, Rath N, Rausch K, Holleczek B; AI-CARE Working Group; Handels H. Survival analysis for lung cancer patients: A comparison of Cox regression and machine learning models. Int J Med Inform. 2024 Nov;191:105607. doi: 10.1016/j.ijmedinf.2024.105607. Epub 2024 Aug 26. PMID: 39208536.

11. Arik, S. Ö., & Pfister, T. (2021). TabNet: Attentive Interpretable Tabular Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 35(8), 6679-6687. https://doi.org/10.1609/aaai.v35i8.16826

12. H. Qi, Y. Hu, R. Fan and L. Deng, "Tab-Cox: An Interpretable Deep Survival Analysis Model for Patients With Nasopharyngeal Carcinoma Based on TabNet," in IEEE Journal of Biomedical and Health Informatics, vol. 28, no. 8, pp. 4937-4950, Aug. 2024, doi: 10.1109/JBHI.2024.3397955.
keywords: {Analytical models;Data models;Predictive models;Cancer;Hazards;Deep learning;Feature extraction;Survival analysis;disease prediction;machine learning algorithms},


