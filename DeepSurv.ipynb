{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cc56b-856a-42d0-9a9d-a69d5e58a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.util import Surv\n",
    "from sklearn.inspection import permutation_importance\n",
    "import optuna\n",
    "import shap\n",
    "from explainability import SHAP\n",
    "from evaluation import evaluate_survival_model, PartialLogLikelihood\n",
    "from training_survival_analysis import train_model\n",
    "from models import MinimalisticNetwork\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "\n",
    "# DeepSurv 사용 위한 Dataset 클래스 정의\n",
    "# 간단한 Dataset 클래스: 이미 수치형 데이터로 준비되었다고 가정. 인코딩 후 사용\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y_time, y_event):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: 입력 특성. Pandas DataFrame 또는 numpy array (수치형 데이터)\n",
    "            y_time: 생존 시간. Pandas Series 또는 numpy array (float)\n",
    "            y_event: 이벤트(실패 여부). Pandas Series 또는 numpy array (0/1 숫자)\n",
    "        \"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.X = X.values.astype(np.float32)\n",
    "        else:\n",
    "            self.X = np.asarray(X, dtype=np.float32)\n",
    "        self.y_time = np.asarray(y_time, dtype=np.float32)\n",
    "        self.y_event = np.asarray(y_event, dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.X[index], dtype=torch.float32),\n",
    "                torch.tensor(self.y_time[index], dtype=torch.float32),\n",
    "                torch.tensor(self.y_event[index], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771088b2-965a-450f-a863-604823afc7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_deepsurv_data(df, time_col, event_col, random_state=1234, test_size=0.1, n_splits=5):\n",
    "    \"\"\"\n",
    "    DeepSurv 모델 학습을 위한 데이터 준비 함수.\n",
    "    \n",
    "    Args:\n",
    "        df: 전처리된 데이터프레임 (결측치 없는 상태)\n",
    "        time_col: 생존 시간을 나타내는 컬럼명 (ex: 'fu_total_yr')\n",
    "        event_col: 생존 여부를 나타내는 컬럼명 (ex: 'survival')\n",
    "        random_state: 재현성을 위한 랜덤 시드\n",
    "        test_size: Train / test set split 비율. 0.1 디폴트\n",
    "        n_splits: cross validation fold 수. 5 디폴트\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test, kfold\n",
    "    \"\"\"\n",
    "    # 독립변수(X) One-Hot Encoding\n",
    "    X = pd.get_dummies(df.drop(columns=[time_col, event_col]), drop_first=True).astype(np.float32)\n",
    "\n",
    "    # 종속변수(y)를 구조화 배열로 변환\n",
    "    y = np.zeros(df.shape[0], dtype=[('vit_status', '?'), ('survival_time', '<f8')])\n",
    "    y['vit_status'] = df[event_col].values.astype(bool)\n",
    "    y['survival_time'] = df[time_col].values.astype(float)\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    model_name = \"deepsurv\"\n",
    "    # 데이터 분할 (Train/Test Split)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # KFold 설정\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e88b88-9bbd-4762-bf3b-c1b06149349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_deepsurv(X_train, y_train, kfold, random_state=1234):\n",
    "    \"\"\"\n",
    "    Optuna를 사용해 DeepSurv 모델의 최적 하이퍼파라미터를 찾는 함수.\n",
    "\n",
    "    Args:\n",
    "        X_train: 훈련 데이터\n",
    "        y_train: 생존 분석 라벨\n",
    "        kfold: K-Fold 객체\n",
    "        random_state: 랜덤 시드\n",
    "\n",
    "    Returns:\n",
    "        best_params: 최적의 하이퍼파라미터\n",
    "    \"\"\"\n",
    "    # 설정 파일 로드\n",
    "    config = yaml.safe_load(Path(\"./config.yaml\").read_text())\n",
    "    base_path = config[\"base_path\"]\n",
    "    device = config[\"device\"]\n",
    "    deepsurv_config = config[\"deep_surv\"]\n",
    "    np.random.seed(random_state)\n",
    "    model_name = \"deepsurv\"\n",
    "\n",
    "\n",
    "    stable_params = {\n",
    "        \"device\": device,\n",
    "        \"input_dim\": X_train.shape[1],\n",
    "        \"loss_fn\": PartialLogLikelihood,\n",
    "        \"epochs\": 300, # epochs 300개 사용\n",
    "        \"model\": \"minimalistic_network\"\n",
    "        }\n",
    "\n",
    "    # DeepSurv 입력값에 맞게 tensor 형태로 변환\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_time = pd.Series(y_train['survival_time'])\n",
    "    y_train_event = pd.Series(y_train['vit_status'])\n",
    "    y_train_time_tensor = torch.tensor(np.ascontiguousarray(y_train_time.values), dtype=torch.float32)\n",
    "    y_train_event_tensor = torch.tensor(np.ascontiguousarray(y_train_event.values), dtype=torch.float32)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_time_tensor, y_train_event_tensor)\n",
    "\n",
    "    def objective_deep_surv(trial):\n",
    "        \"\"\"Optuna에서 사용할 목적 함수\"\"\"\n",
    "        flexible_params = {\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", deepsurv_config[\"batch_size\"]),\n",
    "            \"inner_dim\": trial.suggest_categorical(\"inner_dim\", deepsurv_config[\"inner_dim\"]),\n",
    "            \"lr\": trial.suggest_categorical(\"lr\", deepsurv_config[\"lr\"]),\n",
    "            \"weight_decay\": trial.suggest_categorical(\"weight_decay\", deepsurv_config[\"weight_decay\"])\n",
    "        }\n",
    "        params = {**stable_params, **flexible_params}\n",
    "        scores = []\n",
    "\n",
    "        dataset_test = torch.Tensor(X_test.values)\n",
    "\n",
    "        for train_idx, val_idx in kfold.split(X_train, y_train):\n",
    "            X_train_fold = X_train.iloc[train_idx]\n",
    "            dataset_train = SimpleDataset(X_train_fold, y_train[\"survival_time\"][train_idx], y_train[\"vit_status\"][train_idx]) # class 변환\n",
    "            model, _, _ = train_model(dataset_train, params, trial=trial)\n",
    "\n",
    "            model.eval()\n",
    "            y_pred = model(dataset_test.to(params[\"device\"])).detach().cpu().numpy()\n",
    "            y_pred = y_pred + np.random.random(y_pred.shape) * 1e-7\n",
    "\n",
    "            try:\n",
    "                fold_score = concordance_index_censored(y_test[\"vit_status\"], y_test[\"survival_time\"], np.squeeze(y_pred))[0]\n",
    "            except ValueError: # 예측값에 성공/실패 중 하나가 아예 없는 경우 오류 발생. 해당 과정 스킵\n",
    "                continue\n",
    "            scores.append(fold_score)\n",
    "\n",
    "        return np.mean(scores) if scores else 0.0 # 모든 fold에서 오류가 발생한 경우, 기본값 반환 (예: 0)\n",
    "\n",
    "    # Optuna 실행\n",
    "    study = optuna.create_study(study_name=model_name+str(datetime.datetime.now()),\n",
    "                                direction=\"maximize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=random_state))\n",
    "    study.optimize(objective_deep_surv, n_trials=50)\n",
    "\n",
    "    return study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8c582-fe4d-4f5e-b9f4-c1dea1e42e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_deepsurv(X_train, X_test, y_train, y_test, best_params, kfold, random_state=1234):\n",
    "    \"\"\"\n",
    "    DeepSurv 모델을 학습하고 평가하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test, y_train, y_test: 훈련 및 테스트 데이터\n",
    "        best_params: Optuna에서 찾은 최적 하이퍼파라미터\n",
    "        kfold: K-Fold 객체\n",
    "        random_state: 랜덤 시드\n",
    "    \n",
    "    Returns:\n",
    "        final_scores: 각 fold의 평가 점수 평균값 (Concordance Index 등)\n",
    "    \"\"\"\n",
    "\n",
    "    # 설정 파일 로드\n",
    "    config = yaml.safe_load(Path(\"./config.yaml\").read_text())\n",
    "    base_path = config[\"base_path\"]\n",
    "    device = config[\"device\"]\n",
    "    deepsurv_config = config[\"deep_surv\"]\n",
    "    np.random.seed(random_state)\n",
    "    model_name = \"deepsurv\"\n",
    "\n",
    "    stable_params = {\n",
    "        \"device\": device,\n",
    "        \"input_dim\": X_train.shape[1],\n",
    "        \"loss_fn\": PartialLogLikelihood,\n",
    "        \"epochs\": 300, # epochs 300개 사용\n",
    "        \"model\": \"minimalistic_network\"\n",
    "        }\n",
    "    \n",
    "    fold_scores = {}\n",
    "\n",
    "    for i, (train_fold, val_fold) in enumerate(kfold.split(X_train, y_train)):\n",
    "        X_train_fold = X_train.iloc[train_fold]\n",
    "        X_val_fold = X_train.iloc[val_fold]\n",
    "        \n",
    "        # 학습 데이터셋 생성\n",
    "        dataset_train = SimpleDataset(\n",
    "            X_train_fold,\n",
    "            y_train[\"vit_status\"][train_fold],\n",
    "            y_train[\"survival_time\"][train_fold]\n",
    "        )\n",
    "\n",
    "        # 모델 학습\n",
    "        best_model, _, _ = train_model(dataset_train, {**stable_params, **best_params})\n",
    "        best_model.eval()\n",
    "\n",
    "        # 예측: device에 맞게 Tensor 변환 후 예측 수행\n",
    "        y_pred = best_model(torch.Tensor(X_val_fold.values).to(stable_params[\"device\"])).detach().cpu().numpy()\n",
    "\n",
    "        # 평가: evaluate_survival_model 함수 사용\n",
    "        scores = evaluate_survival_model(best_model, X_val_fold.values, y_train[train_fold], y_train[val_fold])\n",
    "        print(f\"Final DeepSurv Scores in Fold {i}: {scores}\")\n",
    "        fold_scores[f\"fold_{i}\"] = scores  # scores가 dict 형식일 경우 그대로 저장\n",
    "\n",
    "        # Permutation Importance 계산 및 저장\n",
    "        result = permutation_importance(\n",
    "            best_model, X_val_fold, y_train[val_fold], n_repeats=15, random_state=random_state)\n",
    "        result_dict = {k: result[k] for k in (\"importances_mean\", \"importances_std\")}\n",
    "        permutation_importances = pd.DataFrame(result_dict, index=X_val_fold.columns).sort_values(by=\"importances_mean\", ascending=False)\n",
    "        \n",
    "        print(\"Permutation Importances:\")\n",
    "        print(permutation_importances)\n",
    "        \n",
    "        # 각 fold의 permutation importance CSV 파일로 저장\n",
    "        perm_imp_path = f\"DeepSurv_permutation_importances_fold_{i}.csv\"\n",
    "        permutation_importances.to_csv(perm_imp_path, encoding='utf-8')\n",
    "        print(f\"Permutation importances saved to {perm_imp_path}\")\n",
    "\n",
    "        # ---- SHAP values 저장 ----\n",
    "        explainer = shap.Explainer(best_model.predict, X_val_fold.values, feature_names=X_val_fold.columns.tolist())  \n",
    "        shap_values = explainer(X_val_fold.values)\n",
    "        \n",
    "        # ---- SHAP Beeswarm Plot 저장 ----\n",
    "        plt.figure(figsize=(10, 6))  # 적절한 크기 설정\n",
    "        shap.plots.beeswarm(shap_values, show=False)\n",
    "        \n",
    "        beeswarm_path = f\"DeepSurv_beeswarm_fold_{i}.png\"\n",
    "        plt.tight_layout()  # 여백 자동 조정\n",
    "        plt.savefig(beeswarm_path, dpi=300, bbox_inches=\"tight\")  # 잘림 방지\n",
    "        plt.close()  # 메모리 정리\n",
    "        print(f\"Beeswarm plot saved to {beeswarm_path}\")\n",
    "\n",
    "    # Final Scores (5-fold 결과 평균)\n",
    "    fold_scores_df = pd.DataFrame(fold_scores).T\n",
    "    final_scores = fold_scores_df.mean(skipna=True)\n",
    "    print(\"Final DeepSurv Scores:\")\n",
    "    print(final_scores)\n",
    "\n",
    "    return final_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622e125-78f4-409e-84b4-1f6b44687d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# 전처리 ################\n",
    "\n",
    "df = pd.read_csv(\"processed_survival_data_modified.csv\") # processed_survival_data_modified : Age 범주화한 데이터셋\n",
    "df[\"implant_length_group\"] = df[\"implant_length_group\"].apply(\n",
    "    lambda x: \"Length ≥ 10\" if x == \"길이 10 이상\" else \"Length < 10\"\n",
    ")\n",
    "df[\"survival\"] = df[\"survival\"].map({\"survive\": 0, \"fail\": 1}) # 종속변수(수술 성공 여부)를 0, 1로 변환\n",
    "# 분석 제외할 변수 제거\n",
    "exclude_columns = [\"patient_ID\", \"me\", \"failure_reason\", \"failure_date\", \n",
    "                   \"last_fu_date\", \"surgery_Date\", \"fu_for_fail_yr\", \"fu_for_survival_yr\"]\n",
    "all_columns = [col for col in df.columns if col not in exclude_columns] # 분석에 사용할 변수만 포함\n",
    "# 지정한 컬럼들에 결측치가 있는 행 제거\n",
    "df = df.dropna(subset = all_columns)\n",
    "df = df[all_columns]\n",
    "selected_features = [col for col in df.columns if col not in ['fu_total_yr', 'survival'] + exclude_columns]\n",
    "time_col = \"fu_total_yr\"\n",
    "event_col = \"survival\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f169fc7-a2ee-4fcf-948a-ff85640d598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 최종 실행 코드 #############\n",
    "X_train, X_test, y_train, y_test, kfold = prepare_deepsurv_data(df, \"fu_total_yr\", \"survival\")\n",
    "best_params = optimize_deepsurv(X_train, y_train, kfold)\n",
    "fold_scores_df = train_and_evaluate_deepsurv(X_train, X_test, y_train, y_test, best_params, kfold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
