---
title: "통계상담 보고서"
author: 
  - 고준혁, 최재훈
format:
  pdf:
    documentclass: article
    latex-engine: xelatex
    mainfont: Malgun Gothic
    monofont: "D2Coding"
    fontsize: 10pt
    include-in-header:
      text: |
        \usepackage{fontspec}
date: "2025-03-06"
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
```

해당 보고서는 "장애인 환자의 임플란트 생존율"을 분석하는 과정에서 기존의 분석 방법을 평가하고, 발견된 문제점과 개선 방향을 제시한 뒤, 이를 반영하여 개선된 분석을 수행하고 그 결과를 해석하는 방식으로 구성되어있다. 

분석은 총 세 가지 파트로 구성된다. 먼저 기존 분석 방법의 한계를 점검하고, 이를 보완할 수 있는 개선 방향을 간략하게 소개한다. 다음으로는 이러한 개선 사항들을 반영하여 보다 정확하고 신뢰할 수 있도록 개선된 생존분석을 실시하고, 그 결과를 상세히 해석하여 제시한다. 마지막으로는 기존의 통계적 접근법과 차별화된 머신러닝 기법을 적용하여 임플란트 생존율에 대한 분석을 수행하며, 각 분석 결과에 대한 해석과 더불어 두 접근법의 특징을 비교하여 결론을 도출한다.

통계적 방법의 경우, R을 사용하여 분석을 진행하였고 머신러닝 방법의 경우 Python을 사용하여 분석하였다. 또한 각 결과를 확장된 데이터를 가지고 재현할 수 있도록 사용한 사용자 정의 함수에 대한 자세한 설명 및 사용 방법을 명시해두었다.

# 기존 연구 방법의 문제점 및 개선 방향

# 1. 데이터 소개

다음 표는 본 연구에서 사용한 Survival_Analysis_consult.sav 파일의 주요 변수를 요약한 것이다. 각 변수는 환자 정보를 비롯하여 임플란트 수술 및 추적 결과 등을 포함한다. 일부 결측치가 존재하므로 분석 전처리 과정에서 적절한 결측 처리 전략을 적용하였다.

|영문 컬럼|한글 컬럼|설명|
|:-------|:------|:---------|
|patient_ID            |환자 ID                 |환자 고유 식별번호                 |
|me                    |식별 변수(불필요)       |추가 식별 정보                     |
|survival              |생존 여부               |임플란트 생존(1) / 실패(0)         |
|failure_reason        |실패 사유               |임플란트가 실패한 원인             |
|failure_date          |실패일                  |실패 발생 날짜                     |
|last_fu_date          |최종 추적일             |마지막 추적일                      |
|surgery_Date          |수술일                  |임플란트 수술 날짜                 |
|fu_for_fail_yr        |실패 추적기간(년)       |실패한 환자의 추적 기간            |
|fu_for_survival_yr    |생존 추적기간(년)       |생존 환자의 추적 기간              |
|fu_total_yr           |총 추적기간(년)         |모든 환자 대상 총 추적 기간        |
|Sex                   |성별                    |남/녀                              |
|Age                   |나이                    |수술 당시 나이                     |
|type_of_disability_Group2 |장애 유형 그룹2      |환자의 장애 유형을 2차 분류        |
|compliance_with_SPT   |SPT 준수 여부           |유지치료(SPT) 준수(1)/비준수(0)    |
|Systemic_disease      |전신질환 유무/유형      |전신질환 여부                      |
|bone_augmentation_procedure|골증강술 여부      |골증강술 시행(1)/미시행(0)         |
|tooth_loss_reason     |치아상실 원인           |치아상실의 주된 원인               |
|implant_diameter_group|임플란트 직경 그룹      |임플란트 직경을 범주화한 그룹      |
|implant_length_group  |임플란트 길이 그룹      |임플란트 길이를 범주화한 그룹      |
|implant_site          |임플란트 식립 부위      |상악, 하악 내 구체적 위치 구분      |
|jaw                   |턱(상악/하악)           |임플란트가 식립된 턱 위치          |
|prosthesis_type       |보철 유형               |임플란트 상부 보철 형태            |
|periodontal_diagnosis_group|치주 진단 그룹     |치주 상태에 따른 그룹 분류         |

# 2. 기존 연구에 대한 평가

기존 분석에서는 생존분석 방법과 요인 분석에서 몇 가지 개선할 점이 있다. 우선 생존분석에서는 Kaplan-Meier(KM) estimator를 활용하고 있지 않다. 요인 분석이라는 목적에서 비추어봤을 때, **요인별 생존 곡선**과 **log-rank test**를 추가적으로 적용하면 각 요인이 생존율에 미치는 영향을 보다 명확히 시각화할 수 있다.

요인 분석에서는 **변수 간의 교호작용을 충분히 고려하지 않은 점**이 문제로 지적된다. 이를 해결하기 위해 변수 선택 절차를 활용하는 것이 바람직하다. 예를 들어 모든 변수를 넣은 전체 모형(Full model)에서 출발하여 중요하지 않은 변수를 하나씩 제거하는 backward elimination이나, 반대로 최소한의 모형(reduced model)에서 시작해 변수를 추가해 나가는 forward selection과 같은 방법을 통해 보다 최적의 변수 조합을 찾는 것이 권장된다. 변수의 수가 적다면 exhaustive search와 같은 정확한 방법도 가능할 것이다.

변수의 유의성을 평가할 때는 기존 분석에서 사용한 개별 변수의 p-value만으로 평가하기보다는 **AIC**나 **BIC**와 같은 모형 평가 지표(model evaluation metric)를 사용하는 것이 더 적절하다. 또한 연속형 변수와 이산형 변수를 회귀에 함께 사용하는 경우 variance 측면에서 연속형 변수가 불리하기에 연속형 변수를 변수 선택과정에서 제외하는 경우가 많다. 따라서 Age 변수의 경우 가변수화나 정규화 변환을 통해서 모형의 해석 용이성과 일반화 성능이 향상될 것이다.

마지막으로 한 사람당 하나의 임플란트만 식립된 것이 아니기에, 여러 개의 임플란트 식립 상황을 반영하는 **Shared Frailty**를 사용하여 분석을 진행하는 방향이 바람직할 것이다.

---

# 통계적 방법을 이용한 분석

```{r, include=FALSE}
#install.packages("haven")
#install.packages("survival")
#install.packages("KMsurv")
#install.packages("dplyr")
#install.packages("survMisc")
#install.packages("lmtest")
#install.packages("pec")
#install.packages("doParallel")
#install.packages("foreach")
#install.packages("survminer")
#install.packages("gridExtra")
#install.packages("SurvMetrics")
#install.packages("timeROC")
#install.packages("kableExtra")

# 패키지 로드
library(pec)
library(doParallel)
library(survival)
library(KMsurv)
library(lmtest)
library(dplyr)
library(survMisc)
library(haven)
library(foreach)
library(survminer)
library(gridExtra)
library(SurvMetrics)
library(timeROC)
library(kableExtra)
```

```{r, include=FALSE}
raw_data <- read_sav("1. Survival_Analysis_consult.sav") %>%
  mutate(across(where(haven::is.labelled), ~as.numeric(as.factor(.))))

# 설명변수
covariates <- c(
  "Sex",
  "Age_group",
  "type_of_disability_Group2",
  "compliance_with_SPT",
  "Systemic_disease",
  "bone_augmentation_procedure",
  "tooth_loss_reason",
  "implant_diameter_group",
  "implant_length_group",
  "implant_site",
  "jaw",
  "prosthesis_type",
  "periodontal_diagnosis_group"
)
```

# 1. 분석에 사용한 사용자 정의 함수 기능 및 사용방법 
```{r, include=FALSE}
# 결측값 확인 함수 정의
check_missing <- function(data, covariates, delete = FALSE) {
  
  # 결측값 개수 확인
  missing_counts <- data %>%
    select(all_of(covariates)) %>%
    summarise_all(~ sum(is.na(.))) %>%
    t() %>%
    as.data.frame()
  
  colnames(missing_counts) <- "missing_count"
  missing_counts$variable <- rownames(missing_counts)
  rownames(missing_counts) <- NULL
  
  # delete = TRUE일 경우 결측값이 있는 행 삭제
  if (delete) {
    data <- data %>% filter(if_all(all_of(covariates), ~ !is.na(.)))
    message(nrow(data), " rows remaining after deletion.")
    return(data)
  } else {
    return(missing_counts)
  }
}

# 생존곡선 도사 함수
plot_survival_analysis <- function(data, time_var, event_var, covariate = NULL, alpha = 0.05, ylim = c(0, 1)) {
  
  surv_obj <- Surv(time = data[[time_var]], event = data[[event_var]])
  
  if (is.null(covariate)) {
    fit <- survfit(surv_obj ~ 1, data = data, conf.type = "plain")
    
    plot(
      fit,
      mark.time = FALSE,
      xlab = "Time",
      ylab = "Survival Probability S(t)",
      main = "Kaplan-Meier Estimate with 95% CI",
      ylim = ylim,
      lwd = 2
    )
    
    lines(fit, conf.int = TRUE, col = "lightblue")
    
  } else {
    significant_vars <- list()
    
    # p값 계산 후 유의한 변수만 저장
    for (var in covariate) {
      groups <- as.factor(data[[var]])
      logrank_test <- survdiff(surv_obj ~ groups)
      p_value <- 1 - pchisq(logrank_test$chisq, length(logrank_test$n) - 1)
      
      if (p_value < alpha) {
        significant_vars[[var]] <- p_value
        cat(paste0("\n=== Log-rank Test for ", var, " ===\n"))
        cat(paste0("p-value: ", signif(p_value, 4), "\n"))
      }
    }
    
    if (length(significant_vars) == 0) {
      cat("\n유의한 변수가 없습니다. (alpha =", alpha, ")\n")
      return(NULL)
    }
    
    num_vars <- length(significant_vars)
    layout_rows <- ceiling(sqrt(num_vars))
    layout_cols <- ceiling(num_vars / layout_rows)
    
    op <- par(mfrow = c(layout_rows, layout_cols), mar = c(4, 4, 2, 1))
    
    for (var in names(significant_vars)) {
      p_value <- significant_vars[[var]]
      groups <- as.factor(data[[var]])
      group_levels <- levels(groups)
      group_colors <- rainbow(length(group_levels))
      
      fit <- survfit(surv_obj ~ groups, data = data)
      
      plot(
        fit,
        mark.time = FALSE,
        col = group_colors,
        xlab = "Time",
        ylab = "Survival Probability S(t)",
        main = paste0(var),
        ylim = ylim,
        lwd = 2
      )
      
      legend(
        "bottomleft",
        legend = paste0(var, " = ", group_levels),
        col = group_colors,
        lty = 1,
        lwd = 2,
        cex = 0.8
      )
    }
    
    par(op)
  }
}

# global_search를 통한 best model seletion 함수
global_search_cox_cv <- function(data, time_var, event_var, covariates, frailty = NULL, 
                                 cv_folds = 5, time_points = seq(1, 10, by = 1), seed = 1234) {
  set.seed(seed)
  
  covar_combinations <- unlist(lapply(1:length(covariates), function(x) combn(covariates, x, simplify = FALSE)), recursive = FALSE)
  
  cl <- makeCluster(detectCores() - 1)
  registerDoParallel(cl)
  
  results <- foreach(covars = covar_combinations, .combine = rbind, .packages = c("survival", "caret", "dplyr", "timeROC")) %dopar% {
    tryCatch({
      covar_formula <- if (length(covars) > 0) paste(covars, collapse = " + ") else "1"
      
      frailty_term <- if (!is.null(frailty)) paste0(" + frailty(", frailty, ")") else ""
      
      formula <- as.formula(paste0(
        "Surv(", time_var, ", ", event_var, ") ~ ", covar_formula, frailty_term
      ))
      
      # AIC, BIC (전체 데이터)
      full_model <- coxph(formula, data = data, x = TRUE)
      AIC_value <- AIC(full_model)
      BIC_value <- BIC(full_model)
      
      # C-index, AUC (CV로 계산)
      c_index_values <- c()
      auc_values <- c()
      
      folds <- createFolds(data[[event_var]], k = cv_folds, list = TRUE)
      
      for (fold_idx in seq_along(folds)) {
        train_data <- data[-folds[[fold_idx]], ]
        test_data <- data[folds[[fold_idx]], ]
        
        cv_model <- coxph(formula, data = train_data, x = TRUE)
        
        # C-index
        pred_risk <- predict(cv_model, newdata = test_data, type = "lp")
        surv_obj_test <- Surv(test_data[[time_var]], test_data[[event_var]])
        c_index <- survConcordance(surv_obj_test ~ pred_risk)$concordance
        c_index_values <- c(c_index_values, c_index)
        
        # AUC 계산
        auc_result <- tryCatch({
          roc_curve <- timeROC(
            T = test_data[[time_var]],                    
            delta = test_data[[event_var]],              
            marker = pred_risk,              
            cause = 1,                        
            times = time_points,              
            iid = TRUE                        
          )
          mean(roc_curve$AUC, na.rm = TRUE)
        }, error = function(e) NA)
        
        auc_values <- c(auc_values, auc_result)
      }
      
      data.frame(
        ㅡodel = paste(covars, collapse = " + "),
        AIC = AIC_value,
        BIC = BIC_value,
        C_index = mean(c_index_values, na.rm = TRUE),
        AUC = mean(auc_values, na.rm = TRUE)
      )
      
    }, error = function(e) {
      NULL
    })
  }
  
  stopCluster(cl)
  
  if (nrow(results) == 0) {
    cat("\n모든 조합에서 에러가 발생하여 결과가 없습니다.\n")
    return(NULL)
  }

  # best 모델들 정보와 성능 지표 출력
  best_models <- bind_rows(
    results %>% slice(which.min(AIC)) %>% mutate(Criterion = "AIC"),
    results %>% slice(which.min(BIC)) %>% mutate(Criterion = "BIC"),
    results %>% slice(which.max(C_index)) %>% mutate(Criterion = "C_index"),
    results %>% slice(which.max(AUC)) %>% mutate(Criterion = "AUC")  # AUC 기반 모델 추가
  ) %>%
    select(Criterion, Ｍodel, AIC, BIC, C_index, AUC)

  return(best_models)
}

# Cox-Snell residual을 이용한 모델 진단 함수
cox_snell_diagnosis <- function(data, time_var, event_var, covariates) {
  
  # Cox 모델 적합
  formula <- as.formula(paste0("Surv(", time_var, ", ", event_var, ") ~ ", paste(covariates, collapse = "+")))
  cox_model <- coxph(formula, data = data, x = TRUE)
  
  # Cox-Snell 잔차 계산
  cox_snell_residuals <- residuals(cox_model, type = "martingale")
  cs_residuals <- -(cox_snell_residuals - 1)
  
  # Cox-Snell 잔차를 이용한 생존 객체 생성
  surv_obj <- Surv(cs_residuals, event = data[[event_var]])
  
  # Kaplan-Meier 추정
  km_fit <- survfit(surv_obj ~ 1)
  
  # 누적위험함수 계산
  cum_hazard <- -log(km_fit$surv)
  
  # 그래프 출력
  plot(
    km_fit$time, cum_hazard, 
    type = "s", 
    xlab = "Cox-Snell Residuals", 
    ylab = "Cumulative Hazard", 
    main = "Cox-Snell Residuals Model Diagnosis"
  )
  abline(0, 1, col = "red", lty = 2) # y = x 선
  
  return(list(
    cox_model = cox_model,
    cox_snell_residuals = cs_residuals,
    km_fit = km_fit
  ))
}
```

## 1.1 `check_missing()`

**기능**: 특정 변수들(`covariates`)에서 결측치(NA) 개수를 확인하고, `delete=TRUE`를 설정하면 해당 결측이 포함된 행을 모두 제거한 데이터를 반환한다.

**매개변수**:
- `data`: 분석할 데이터
- `covariates`: 결측치 확인 대상 변수 목록
- `delete`: 결측이 포함된 행을 제거할지 여부 (기본값: `FALSE`)

> **주의**: 결측치가 많으면 유효 표본 수가 줄어들 수 있으며, `delete=TRUE`로 인해 데이터 손실이 있을 수 있으므로 주의가 필요하다. \([5]\)

**사용방법**:
```{r, eval=FALSE}
# 결측 개수 확인
check_missing(raw_data, covariates)  
# 결측치가 포함된 행 제거한 데이터 반환
check_missing(raw_data, covariates, delete=TRUE)  
```

## 1.2 `plot_survival_analysis()`

**기능**: **Kaplan-Meier 생존곡선**을 그리며, 특정 변수별 생존곡선 비교를 수행할 수 있다. 특정 변수별 생존곡선 비교를 실행하는 경우, Log-rank test를 진행하며 해당 검정에서 유의한 변수들의 검정 결과와 생존곡선만을 그린다.

**매개변수**:
- `data`: 분석할 데이터
- `time_var`: 생존 시간 변수
- `event_var`: 사건 발생 여부 변수
- `covariate`: 비교할 그룹 변수 (기본값: `NULL`)
- `alpha`: 유의수준 (기본값: `0.05`)
- `ylim`: y축 범위 (기본값: `c(0,1)`)

**사용방법**:
```{r, eval=FALSE}
# 전체 생존곡선
plot_survival_analysis(data, "fu_total_yr", "survival")
# 변수별 생존곡선
plot_survival_analysis(data, "fu_total_yr", "survival", covariate = "Age_group")  
```

KM 곡선을 통해 시간이 지남에 따른 생존율 변화를 직관적으로 파악할 수 있고, Log-rank 검정을 통해 두 그룹 이상 간 생존함수 차이가 통계적으로 유의한지 확인할 수 있다. \([1]\)

## 1.3 `global_search_cox_cv()`

**기능**: Cox 회귀분석을 수행하며, 다양한 변수 조합을 탐색하여 최적 모델을 선정한다. 모델 선택은 (1)**AIC** (2)**BIC** (3) **C-index** (4) **time-dependent AUC** 의 네가지 평가지표를 기준으로 진행하며 각 기준에서 최적의 성능을 보이는 모델을 식별한다. 결과는 각 최적 모델에 대한 지표값을 요약한 표를 반환한다.

**매개변수**:
- `data`: 분석할 데이터
- `time_var`: 생존 시간 변수
- `event_var`: 사건 발생 여부 변수
- `covariates`: 고려할 설명변수 목록
- `frailty`: 공유 프레일티 모형 적용 여부 (기본값: `NULL`) / 적용하는 경우, 해당 변수명 입력
- `cv_folds`: 교차검증 폴드 수 (기본값: `5`)
- `time_points`: 시간 종속 AUC를 계산할 시점 벡터 (기본값: `seq(1,10, by=1)`), 즉, AUC가 계산될 시점들을 입력
- `seed`: 난수 시드 설정 (기본값: `1234`)

**사용방법**:
```{r, eval=FALSE}
result <- global_search_cox_cv(data, "fu_total_yr", "survival", covariates)
result_frailty <- global_search_cox_cv(data, "fu_total_yr", "survival", 
                                       covariates, frailty="patient_ID")
```

## 1.4 `cox_snell_diagnosis()`

**기능**:  Cox 회귀모델에 대해 Cox-Snell 잔차를 계산하고, 이 잔차를 기반으로 누적위험함수를 추정함으로써 모델 적합도를 진단한다. (Klein et al., 2003) 분석 데이터가 Cox 모델을 적합하는게 적절한지 진단하는 방법으로 해당 분석에서는 사용하였다.

**매개변수**:
- `data`: 분석할 데이터
- `time_var`: 생존 시간 변수
- `event_var`: 사건 발생 여부 변수
- `covariates`: Cox 모델에 포함할 변수 목록

**사용방법**:
```{r, eval=FALSE}
diagnosis <- cox_snell_diagnosis(data, "fu_total_yr", "survival", covariates)
```

잔차의 누적위험함수를 그래프로 표시했을 때, y = x 직선에 가깝게 분포하면 모델이 자료를 적절히 설명하고 있음을 시사한다.


# 2. 데이터 전처리

1.**나이변수 범주화**
```{r}
raw_data <- raw_data %>%
  mutate(Age_group = factor(case_when(
    Age < 40 ~ "Under 40",
    Age >= 40 & Age < 60 ~ "40-59",
    Age >= 60 ~ "60 and over"
  ), levels = c("Under 40", "40-59", "60 and over")))
```

연령을 연속형 대신 세 구간(40세 미만, 40-59세, 60세 이상)으로 범주화하였다. 이는 임상적으로 유의한 연령 구간을 설정하고, 나이에 따른 그룹 간 생존율 차이를 간편히 비교하기 위함이다. 또한, Cox regression을 사용한 변수 선택에서 데이터 형태를 통일하여 bias를 막기 위함도 있다.

2. **결측치 처리**: 
```{r}
data = check_missing(raw_data, covariates, delete = T)
```
`check_missing()` 함수를 통해 주요 설명변수(`covariates`)에 결측치가 있는 행을 제거하였다. 이는 분석 대상을 결측 없는 완전 사례로 한정하기 위함이며, 결측치의 양이 많을 경우 다른 방법(대치법 등)을 고려할 수 있다.현재의 분석 상황에서는 결측치가 있는 사례가 한 가지이기에 제거하는 방법을 택했다.

3. **불필요한 변수 제거**:
```{r}
data <- data %>%
  select(-c("me", "Age", "failure_reason", "failure_date", 
            "last_fu_date", "surgery_Date", "fu_for_fail_yr",
            "fu_for_survival_yr"))
```

분석 목적과 직접 관련 없는 변수(예: `me`, `failure_reason` 등)를 제거하여 최종 분석용 데이터(`data`)를 구성하였다.

# 3. 모델 평가지표 및 분석방법 설명

## 3.1 분석방법 개요

### 3.1.1 생존함수와 검열(Censoring)
- **생존시간** $T$ 은 어떤 사건(예: 사망, 재발 등)까지 걸리는 시간을 의미한다.
- **생존함수**는
$$
S(t) = P(T > t),
$$
즉 시점 $t$ 까지 사건이 발생하지 않고 생존해 있을 확률이다.
- **위험함수(Hazard function)**는
$$
h(t) = \lim_{\delta t \to 0} \frac{P(t \le T < t + \delta t \mid T \ge t)}{\delta t} 
= \frac{f(t)}{S(t)},
$$
여기서 $f(t)$는 생존시간의 확률밀도함수이다.
- **검열(censoring)**이란 관측 종료 시점까지 사건 발생이 관측되지 않은 경우(오른쪽 검열) 등을 말한다. 이러한 검열된 데이터까지 고려하여 분석해야 한다는 점에서, 일반적인 회귀분석과 다른 접근이 필요하다 \([1, \text{p.63–90}]\).

### 3.1.2 Kaplan-Meier 추정 (KM 추정)
- 사건 발생 시점들을 시간 순서대로 $t_{(1)}, t_{(2)}, \cdots, t_{(r)}$ 라 하고, 해당 시점에서 사건이 발생하는 관측수를 $d_j$, 해당 시점 직전에 위험집단에 속한 수를 $n_j$ 라 할 때,

$$
\hat{S}(t) = \prod_{t_{(j)} \le t} \left( 1 - \frac{d_j}{n_j} \right).
$$
- KM 추정을 통해 시간에 따른 생존확률을 시각화한 **생존곡선**(Kaplan-Meier curve)을 얻을 수 있다. 이를 통해 시간 경과에 따른 사건 발생 패턴을 직관적으로 파악할 수 있다 \([1]\).

### 3.1.3 Log-rank test
- **두 그룹 이상**의 생존함수를 비교하기 위해 사용되는 검정.
- 각 사건 발생 시점에서 그룹별 위험집단(사건이 아직 발생하지 않은 표본) 크기를 바탕으로 관측된 사건 수와 기대 사건 수를 비교하여 검정 통계량을 구한다.
- 예: 두 그룹(A, B)이 있다고 할 때, 어떤 시점 $t_j$ 에서
  - 그룹 A에서 사건 발생: $d_{j,A}$, 위험집단: $n_{j,A}$
  - 그룹 B에서 사건 발생: $d_{j,B}$, 위험집단: $n_{j,B}$
  - 전체 사건 수: $d_j = d_{j,A} + d_{j,B}$, 전체 위험집단: $n_j = n_{j,A} + n_{j,B}$
  - 그룹 A에서 기대 사건 수: $\frac{n_{j,A} \times d_j}{n_j}$
- 이러한 방식으로 전체 사건 시점을 합산하여 카이제곱(chi-square) 검정 통계량을 계산하고, **생존곡선의 차이가 통계적으로 유의한지** 확인한다.

### 3.1.4 Cox 회귀분석 (Cox proportional hazards model, coxph)
- 생존시간에 영향을 미치는 여러 독립변수(공변량)를 고려하기 위한 반(半)모수적 모형 \([7, \text{p.40–45}]\).
- **비례위험가정(Proportional Hazards Assumption)**: 공변량 변화가 "위험함수 $h(t)$"에 승수적인(배수) 영향을 미치며, 시간에 따라 위험비(Hazard Ratio)가 일정하다는 가정.
- 모형 식:
$$
h(t \mid X) = h_0(t) \exp(\beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_p X_p),
$$
  - $h_0(t)$: **기준위험함수(baseline hazard)** (비모수적으로 추정)
  - $\beta_i$: 추정해야 할 회귀계수
- **부분가능도(Partial Likelihood)**를 통해 $\beta$ 를 추정한다. 전체 파라미터(기준위험함수 포함)를 모두 추정하지 않고, 사건 발생 순서 정보로부터 $\beta$ 만을 추정하게 된다.

### 3.1.5 Cox-Snell 진단
- **모델 적합도(goodness-of-fit)를 평가**하기 위해 사용하는 잔차(residual) 분석 기법 \([7, \text{p.81–83}]\).
- Cox-Snell 잔차 $r_i$ 는 각 관측치 $i$의 누적위험함수(estimated cumulative hazard) 값을 이용하여 정의된다:

$$
r_i = \hat{H}(T_i) = -\log(\hat{S}(T_i))
$$

- 만약 모형이 자료를 잘 설명한다면, $r_i$들은 (이상적으로) 지수분포(평균 1)를 따르게 되며, 누적 위험함수 플롯에서 $y = x$ 직선 부근에 점들이 고루 분포한다.

### 3.1.6 Shared Frailty 모형
- **Shared frailty** 모형은 생존분석에서 집단(clusters) 내의 관측치 간 상관성을 고려하기 위한 확장 모형이다.
- 생존시간 $T_{ij}$ (관측치 $j$가 그룹 $i$에 속한 경우)에 대한 위험함수는 다음과 같다.
$$
h_{ij}(t|\alpha_i) = h_0(t)\alpha_i \exp(\mathbf{X}_{ij}'\boldsymbol{\beta})
$$

- $\alpha_i$: 그룹(클러스터) 별 frailty 효과
- 그룹 내 개체들은 동일한 $\alpha_i$ 값을 공유하며, 그룹 간 이질성을 설명할 수 있다 \([2]\).

## 3.2 모델 평가지표

### 3.2.1 AIC (Akaike Information Criterion)
$$
\text{AIC} = -2 \times \log L + 2k,
$$
여기서,
- $\log L$: 모델의 최대우도값,
- $k$: 추정해야 할 모수(파라미터) 수

값이 작을수록 자료에 잘 적합된 모델(단, 복잡도도 함께 고려)로 볼 수 있다 \([6]\).

### 3.2.2 BIC (Bayesian Information Criterion)
$$
\text{BIC} = -2 \times \log L + k \log(n),
$$
여기서,
- $n$: 표본 크기

AIC와 유사하나, 표본 크기를 고려하여 복잡한 모델에 대해 더 강한 패널티를 부과한다. AIC, BIC는 “모델이 주어진 자료를 얼마나 잘 설명하는가”라는 **추론(inference)** 관점에서 중요하다 \([3]\).

### 3.2.3 C-index (Concordance Index)
- 생존분석에서 예측된 위험도(risk score) 순위와 실제 사건 발생 순서의 일치도를 나타내는 지표.
- 0.5 (무작위 수준)에서 1.0 (완벽 예측) 사이 값을 갖는다.
- Cox 모형 등에서 **예측 성능을 평가**하기 위한 핵심 지표로 활용되며, Harrell(2001)에 자세한 논의가 있다. \([3, \text{p.462–465}]\).

### 3.2.4 AUC (Area Under the ROC Curve)
- **ROC 곡선**(민감도 vs. 1-특이도) 아래 면적으로, 예측력이 높을수록 1에 가까워진다.
- 생존분석에서는 **시간 의존(time-dependent) AUC**를 고려할 수 있으며, 특정 시점 $ t $에서 사건 발생 여부 예측을 평가한다 \([4]\).
- 0.5 (무작위)에서 1.0 (완벽 예측) 범위를 갖는다.

### 3.2.5 교차검증(Cross Validation, CV)
- 데이터를 여러 개 폴드(fold)로 나눈 뒤, 한 폴드를 검증용(Validation)으로, 나머지를 학습용(Training)으로 사용한다. 이를 폴드 개수만큼 반복한다.
- 예측 성능 지표(C-index, AUC 등)에 대해 각 폴드에서 계산한 값을 평균해 최종 성능을 추정한다.
- **과적합(Overfitting)** 문제를 방지하고 **모델의 일반화 성능**을 더 공정하게 평가할 수 있다 \([5]\).

## 3.3 모델 선택 전략
- **AIC, BIC**는 자료 적합도(모델 설명력)와 복잡도(변수 수)를 함께 고려하므로, “현상 설명”이나 “추론” 목적일 때 주로 사용 \([6]\).
- **C-index, AUC**는 “새로운 데이터(또는 검증 세트)에 대한 예측 정확도”를 반영하는 지표로, “예측” 목적일 때 더 중점적으로 고려.
- **교차검증**을 통해 (C-index, AUC 등) 예측 성능을 추정하여, 여러 후보 모형을 비교한다.
- 종합적으로 AIC/BIC (추론 관점)과 C-index/AUC (예측 관점)를 모두 검토하여 최적 모델을 선택한다.

# 4. 분석 결과 및 해석
## 4.1 Kaplan-Meier Analysis
### 4.1.1 생존함수 추정(KM-estimator) 및 생존곡선
```{r, fig.width=8, fig.height=5, out.width='60%', fig.align='center'}
plot_survival_analysis(
  data = data,
  time_var = "fu_total_yr",
  event_var = "survival",
  ylim = c(0.8, 1)
)
```
다음은 KM 추정법을 사용하여 전체 데이터에 대한 생존 확률을 추정한 그래프이다. x축은 시간(년)이며 y축은 생존 확률이다. 측정한 최장기간을 고려하더라도 추정 생존 확률이 0.9를 상회하는 것을 확인할 수 있다. 따라서 전체적으로 임플란트의 장기 생존율이 높다고 할 수 있다. 구체적으로는 8년에서 10년 사이 다소 급격한 추정 생존율 하락하는 것을 통해 해당 기간에 임플란트 탈락 가능성이 높다고 추론할 수 있다다.

### 4.1.2 각 요인별(설명변수별) Log-rank test 및 생존곡선
```{r}
plot_survival_analysis(
  data = data,
  time_var = "fu_total_yr",
  event_var = "survival",
  covariate = covariates,
  ylim = c(0.7, 1)
)
```
해당 결과는 각 설명 변수별 level에 따른 생존곡선의 차이를 검정하는 Log-rank test를 진행하고 이에 따른 유의 변수들의 검정 결과와 생존 곡선을 나타낸다. **장애 유형과 식립 위치, 보철 유형**에 따른 생존율의 차이가 유의하다는 결과를 확인할 수 있고 이는 각 변수들의 level에 따른 생존 곡선을 통해서도 확인할 수 있다.

## 4.2 요인 분석을 위한 Cox regression (모델 선택)

### 4.2.1 Shared Frailty를 고려하지 않은 모델
```{r}
#result <- global_search_cox_cv(data, time_var = "fu_total_yr", 
#                               event_var = "survival", covariates = covariates)
result <- read.csv("no_frailty_result.csv")

result %>%
  mutate_if(is.numeric, round, 2) %>%
  kbl(booktabs = TRUE, caption = "Model Selection Results - without Shared Frailty") %>%
  column_spec(2, width = "8cm") %>% # 2번째 컬럼(모델 설명 컬럼) 폭 조정
  kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)
```

임플란트 탈락에 영향을 주는 요인 분석을 위해 Shared Frailty를 고려하지 않은 모델의 변수 선택을 진행하였으며 위와 같은 변수 선택 결과를 확인할 수 있다. 데이터의 설명력 측면에서 해석 가능한 AIC, BIC 기준의 식별 모델의 경우, 앞서 진행한 Log-rank test에서 유의 변수로 식별한 **장애 유형**과 **식립 위치**가 공통적으로 유의한 변수로 선택되었음을 알 수 있다. 또한 AIC, BIC 기준 식별 모델 모두에서 **치아 상실 원인**도 임플란트 탈락에 영향을 주는 요인으로 선택되었다. 이외 AIC 기준 식별 모델에서 **연령층, 보철 유형, 치주 상태** 등이 영향을 주는 변수로 선택되었다.

예측에 주안점을 둔 C-index와 AUC를 기준으로 모델을 식별한 경우, 설명력에 주안점을 둔 모델들과는 다르게 새로운 변수들이 추가되거나 제거되는 것을 확인할 수 있다. 다만 절대적인 C-index와 AUC의 수치를 보았을 때, 예측력의 측면에서 강점을 가지는 모델이며 이렇게 선택한 변수가 임플란트 탈락을 예측하는데 영향을 주는 변수라고 말하기 어려운 수준이다.

### 4.2.2 Shared Frailty를 고려한 모델
```{r}
#result_frailty <- global_search_cox_cv(data, time_var = "fu_total_yr", event_var = "survival", 
#                                       covariates = covariates, frailty = "patient_ID")
result_frailty <- read.csv("frailty_result.csv")

result_frailty %>%
  mutate_if(is.numeric, round, 2) %>%
  kbl(booktabs = TRUE, caption = "Model Selection Results - with Shared Frailty") %>%
  column_spec(2, width = "8cm") %>% # 2번째 컬럼(모델 설명 컬럼) 폭 조정
  kable_styling(latex_options = c("HOLD_position"), full_width = FALSE)
```

임플란트 탈락에 영향을 주는 요인 분석을 위해 Shared Frailty를 고려한 모델의 변수 선택을 진행하였으며 위와 같은 변수 선택 결과를 확인할 수 있다. 앞선 결과와 마찬가지로 AIC, BIC 기준 식별 모델의 경우 **장애 유형**과 **식립 위치**, **치아 상실 원인**가 공통적으로 유의한 변수로 선택되었으며 추가적으로 **연령층, SPT 준수 여부, 전신 질환, 치주 상태** 변수가 유의 변수로 공통적으로 선택되었다. 이외 **임플란트 직경**의 경우 BIC 기준 모델에서 유의 변수로 선택되었음을 확인할 수 있다.

예측의 경우, 앞선 Shared Frailty를 고려하지 않은 모델과 대게 동일한 결과를 확인할 수 있다. 이 또한 C-index와 AUC의 수치를 보았을 때, 예측력의 측면에서 강점을 가지는 모델이며 이렇게 선택한 변수가 임플란트 탈락을 예측하는데 영향을 주는 변수라고 말하기 어려운 수준이다.

전반적으로 변수가 Shared Frailty를 고려하지 않은 모델들에 비해 많은 변수들이 선택되는 것을 확인할 수 있다.

# 5. 기타 이슈
## 5.1 데이터 부족
```{r, fig.width=8, fig.height=5, out.width='60%', fig.align='center'}
# 예시: AIC 기준 최적 모델 선택
best_model_vars <- strsplit(result$model[1], " \\+ ")[[1]]

# cox_snell_diagnosis 실행
diagnosis <- cox_snell_diagnosis(
  data = data,
  time_var = "fu_total_yr",
  event_var = "survival",
  covariates = best_model_vars
)
```

현재 대부분의 모델에서 다음과 같이 Cox-Snell Residual을 사용하여 추정한 Cumlative Hazard가 다음과 같이 나타난다. 이는 데이터 자체의 부족과 데이터 내 실패 사례들의 부족으로 인한 현상으로 실패 사례가 충분한 데이터 보충으로 해결할 수 있을 것이다. 

---

# 머신러닝 방법을 이용한 분석

## 1. Random Survival Forest (RSF)

### 1.1 개요

Random Survival Forest(RSF)는 기존의 랜덤 포레스트(Random Forest)를 생존분석에 적용한 방법으로, 시간-사건 데이터(time-to-event data)를 분석할 수 있도록 확장된 모델이다. 랜덤 포레스트가 다수의 의사결정나무(Decision Tree)를 앙상블하여 예측 성능을 높이는 방식과 유사하게, RSF는 생존 데이터에서 여러 개의 생존 나무(Survival Tree)를 훈련하고 이들의 결과를 종합하여 예측한다.

### 1.2 특징

- **비모수적(non-parametric) 방법**: 특정한 분포 가정을 필요로 하지 않으며 데이터의 구조를 유연하게 반영할 수 있다.
- **검열 데이터(censored data) 처리**: 일반적인 회귀 및 분류 모델과 달리 생존시간 데이터에서 검열(censoring)된 값을 효과적으로 처리할 수 있다.
- **생존 확률 및 누적위험 계산**: 개별 노드에서 누적위험률(cumulative hazard rate)과 생존 확률(survival rate)을 계산하여 예측을 수행한다.

## 2. DeepSurv \([9]\)

### 2.1 개요

**DeepSurv**는 신경망(Neural Network, NN) 기반의 생존분석 모델로, Cox 비례위험 모형(Cox Proportional Hazard Model, CoxPH)을 확장한 형태이다. 딥러닝 기법을 적용하여 복잡한 변수 간의 관계를 학습하고, 개인별 생존 리스크를 예측할 수 있도록 설계되었다.
비례위험 가정 $h(t|X) = h_0(t) \cdot \exp(r(X))$에서 $r(X)$를 추정하는 과정에서 **DeepSurv**라는 딥러닝 기법을 적용했다.

### 2.2 모델 세부 설명

```{r, echo=FALSE, fig.align='center', out.width="80%"}
knitr::include_graphics('deepsurv.webp')
```


DeepSurv 모델의 다이어그램은 위와 같다. 기본적인 딥러닝의 feed-forward deep neural network의 구조를 띠고 있다. 모델의 output $\hat{h}_{\theta}(x)$는 모델을 통해 예측된 log-risk function이다.
학습에 사용되는 loss function, 즉 $\hat{\theta}$를 추정 과정에서 최소화하는 함수는 다음과 같다.
$$
l(\theta) := -\frac{1}{N_{E=1}} \sum_{i: E_i=1} \left( \hat{h}_\theta(x_i) - \log \sum_{j \in \mathcal{R}(T_i)} e^{\hat{h}_\theta(x_j)} \right) + \lambda \cdot \|\theta\|_2^2,
\text{where } \mathcal{R}(t) = \{ i : T_i > t \}
$$

위 loss function은 CoxPH와 다른 형태를 띠고 있다. CoxPH의 loss function은 다음과 같다.
$$
L_c(\beta) = \prod_{i: E_i=1} \frac{\hat{r}_\beta(x_i)}{\sum_{j \in \mathcal{R}(T_i)} \hat{r}_\beta(x_j)}
= \prod_{i: E_i=1} \frac{\exp(\hat{h}_\beta(x_i))}{\sum_{j \in \mathcal{R}(T_i)} \exp(\hat{h}_\beta(x_j))},
$$
Loss function을 최소화하는 $\hat{\theta}$를 찾는 과정은 여러 방법이 있지만, 이 논문과 우리의 연구에서는 **Adaptive Moment Estimation (Adam) for the gradient descent algorithm**을 이용했다.

### 2-3. Treatment recommender system (치료 추천 시스템) : CoxPH와 비교 했을 때의 장점
DeepSurv 참고문헌\([9]\)에서 DeepSurv가 CoxPH에 대해 가질 수 있는 장점으로 **치료 추천 시스템**을 설명하고 있다.

#### 개요
임상 연구에서 환자는 개별적인 예후 요인과 받는 치료에 따라 서로 다른 위험 수준을 갖는다. 이를 일반화하여 모든 환자를 $n$개의 치료 그룹 중 하나에 할당한다고 가정한다. 각 치료 $i$에 대해 독립적인 위험 함수 $e^{h_i(x)}$를 설정하면, 전체 위험 함수는 다음과 같이 표현된다.
$$ \lambda(t; x|\tau = i) = \lambda_0(t) \cdot e^{h_i(x)} $$

#### 치료 추천 함수
환자의 특정 치료 $i$에 대한 로그-위험 값 $h_i(x)$를 정확히 예측하는 것이 중요하다. 각 환자가 동일한 기본 위험 함수 $\lambda_0(t)$를 갖는다고 가정하면, 위험비(Hazard Ratio)의 로그 값을 활용하여 특정 치료 옵션에 대한 개인별 위험비를 계산할 수 있다. 이를 **추천 함수(recommender function)**라고 하며, 다음과 같이 정의된다.

$$
 \text{rec}_{ij}(x) = \log \left(\frac{\lambda(t; x|\tau = i)}{\lambda(t; x|\tau = j)}\right) = h_i(x) - h_j(x)
$$
즉, 특정 치료 $i$와 치료 $j$ 간의 위험도를 비교하는 값이다.

#### 추천 함수의 활용
- 환자를 네트워크에 한 번 입력하여 치료 그룹 $i$에 대한 결과를 얻고, 다시 치료 그룹 $j$에 대한 결과를 얻은 후 두 값을 비교한다.
-만약 **추천 함수 값이 양수**이면, 치료 $i$가 치료 $j$보다 사망 위험이 높음을 의미하므로, 환자에게 치료 $j$를 추천해야 한다.
-반대로 **추천 함수 값이 음수**이면, 치료 $i$가 더 효과적이며, 사망 위험이 치료 $j$보다 낮음을 의미하므로 치료 $i$를 권장한다.

#### DeepSurv의 장점
-DeepSurv는 CPH(Cox Proportional Hazards) 모델보다 치료 추천 측면에서 유리하다.
—DeepSurv는 **사전에 치료 상호작용 항을 정의하지 않고** 자동으로 추천 함수를 계산할 수 있다.
—반면, CoxPH 모델에서는 **치료 상호작용 항이 포함되지 않으면 추천 함수가 일정한 값으로 유지**된다.
- 치료 간의 상호작용을 발견하는 것은 실험 비용이 많이 들거나 의학적 지식이 필요하므로, DeepSurv는 CoxPH보다 효율적인 솔루션이다.

## 3. TabNet

### 3.1 개요

**TabNet**은 테이블 데이터(Tabular Data, 정형 데이터) 처리에 특화된 딥러닝 모델로, 어텐션 메커니즘을 활용하여 데이터를 학습하는 방식이다.  
생존분석에서의 적용 사례가 드물지만, 본 연구에서는 생존분석을 위해 **CoxPH의 손실 함수를 적용하여 TabNet을 사용**하였다.  
DeepSurv와 마찬가지로 **비례위험 가정**을 두고 있으며, \(r(X)\)를 추정하는 과정에서 **TabNet 알고리즘**을 적용했다.

### 3.2 특징

- **어텐션 메커니즘 활용**  
  TabNet은 학습 과정에서 **각 변수(feature)에 대한 어텐션(attention) 가중치를 학습하여 중요한 변수에 집중할 수 있도록 한다**.
- **해석 가능성**  
  기존의 딥러닝 모델보다 해석 가능성이 높아, **의료 및 생명과학 분야에서 신뢰할 수 있는 모델로 활용될 가능성이 크다**.
- **생존분석 적용**  
  본 연구에서는 **TabNet의 기본 손실 함수를 CoxPH 기반의 손실 함수로 변경하여 생존분석 문제에 적용**하였다.

## 4. 모델의 설명 가능성 (Explainability) 분석

위에 기술한 **RSF, DeepSurv, TabNet** 세 가지 분석 방법은 **머신러닝 방법을 사용하므로 전통적인 CoxPH보다 모델 해석이 어렵다**.  
따라서 머신러닝 모델의 결과를 해석하는 데 도움이 되는 **Feature Importance 기법**을 적용하였다.  
본 논문에서는 두 가지 주요 설명 가능성 분석 기법을 활용하였다.

### **4.1 Permutation Feature Importance**

* 변수의 중요도를 평가하는 방법으로,  
  **원본 데이터와 특정 변수를 랜덤하게 섞은 데이터의 모델 성능 차이를 비교하여 변수의 중요도를 측정**한다.
* 중요한 변수일수록 변형된 데이터에서 모델 성능이 크게 감소하며,  
  이를 통해 변수별 영향도를 확인할 수 있다.
* 다중공선성에 취약하다는 단점이 있다.

### **4.2 SHAP (SHapley Additive exPlanations)**
* SHAP은 머신러닝 모델에서 개별 변수(feature)가 예측 결과에 미치는 영향을 정량적으로 분석하는 방법이다.
* 변수 간의 모든 가능한 상호작용을 고려하여 특정 변수의 기여도를 계산할 수 있다.
* 모델이 특정 결과를 도출한 이유를 설명하는 데 활용할 수 있으며, 특히 비선형 모델(예: DeepSurv, TabNet)에서 해석력을 높이는 데 유용하다.

## **5. 모델 평가 지표**

본 논문에서는 모델의 성능을 평가하기 위해  
**Concordance-Index (C-Index), Integrated Brier Score (IBS), Cumulative AUC (Area Under the Curve)**  
세 가지 주요 지표를 활용하였다.

### **5.1 Concordance Index (C-Index, 순위 일관성 지수)**

$$
C = \frac{\sum_{i,j} I(T_i < T_j) I(\hat{r}_i > \hat{r}_j)}{\sum_{i,j} I(T_i < T_j)}
$$

- **정의:**  
  C-Index는 **예측된 위험도(risk score)와 실제 생존 시간의 일관성을 측정하는 지표**이다.
- **설명:**  
  두 개의 비교 가능한 샘플 \((i, j)\)에 대해, 실제로 **생존 시간이 짧은 샘플이 더 높은 위험도(\(\hat{r}\))를 갖는 경우**  
  해당 예측이 올바른 것으로 간주된다.
- **해석:**  
  - $ C = 1 $이면 모델이 완벽하게 예측한 것이며,  
  - $ C = 0.5 $는 무작위 예측과 동일한 수준을 의미한다.


### **5.2 Integrated Brier Score (IBS, 통합 Brier 점수)**

$$
IBS = \int_0^{t_{\max}} \frac{1}{N} \sum_{i=1}^{N} (S(t | X_i) - Y_i(t))^2 dt
$$

- **정의:**  
  Brier Score는 특정 시간 $t$에서 **실제 생존 여부**와 **예측된 생존 확률** 간의 평균 제곱 오차(Mean Squared Error, MSE)를 측정하는 지표이다.
- **설명:**  
  - censoring(중도 절단)을 고려한 생존 분석에 적합한 지표이며,  
  - 특정 시점이 아닌 여러 시점에 걸쳐 측정된 값을 통합하여 **시간 전반에 걸친 예측 오류를 평가**한다.
- **해석:**  
  - **Brier Score가 0에 가까울수록 모델의 예측 정확도가 높음**을 의미한다.

### **5.3 Cumulative Area Under the Curve (Cumulative AUC, 누적 AUC)**

$$
AUC(t) = P(\hat{r}_i > \hat{r}_j | T_i \leq t, T_j > t)
$$

- **정의:**  
  누적 AUC는 특정 시간 \(t\)까지 이벤트(사건)가 발생한 개체와  
  아직 생존한 개체 간의 위험도(risk score) 차이를 비교하는 지표이다.

### **결론**
- 본 연구에서는 생존분석을 위해 **CoxPH, RSF, DeepSurv, TabNet** 네 가지 모델을 비교하였다.
- 모델의 설명 가능성을 높이기 위해 **SHAP 및 Permutation Feature Importance 기법을 활용**하였다.
- **C-Index, IBS, Cumulative AUC**를 통해 모델 성능을 정량적으로 평가하였다.

## **6. 모델 학습 방법**

### **6.1 전처리**
머신러닝 방법에 적용 전, 범주형 변수들을 인코딩해야 한다.  
**RSF**와 **DeepSurv**에서는 **One-hot encoding**을 사용했고, **TabNet**에서는 **Label encoding**을 사용했다.

- **One-hot encoding:**  
  범주형 변수를 여러 개의 **이진(0/1) 변수**로 변환하는 방식  
  예) `"A", "B", "C"` → `[1,0,0]`, `[0,1,0]`, `[0,0,1]`
  
- **Label encoding:**  
  범주형 변수를 **정수(integer) 값**으로 변환하는 방식  
  예) `"A", "B", "C"` → `0, 1, 2`

### **6.2 교차 검증 (Cross Validation)**

본 연구에서는 **5-fold cross validation**을 적용하였다.

### **6.3 하이퍼파라미터 튜닝**

각 모델의 최적 성능을 찾기 위해 **하이퍼파라미터 최적화**를 수행하였다.  
본 연구에서는 **Optuna**를 사용하여 하이퍼파라미터 탐색을 진행하였다.

**Optuna 최적화 과정:**
1. 미리 정의된 하이퍼파라미터 범위에서 **무작위로 값을 선택(trial)**  
2. 선택된 하이퍼파라미터를 사용하여 모델을 학습하고 성능을 평가  
3. **50번의 trial을 반복**한 후,  
   **Concordance Index(C-Index)가 가장 높은 하이퍼파라미터**를 최종 모델에 적용  

Optuna의 설정값은 **`config.yaml`** 파일에서 정의되어 있으며,  
각 모델별 적절한 하이퍼파라미터의 범위를 설정하여 탐색하였다.

### **6.4 모델 간 비교**

최적의 하이퍼파라미터를 찾은 후, 이를 이용하여 **모델을 학습하고 성능을 비교**하였다.  
모델 비교는 **Concordance Index (C-Index), Integrated Brier Score (IBS), Cumulative AUC**를 기반으로 수행되었다.

5-fold cross validation을 통해 **각 모델의 성능을 측정**하고,  
데이터 분할 방식(split)에 따라 **성능 차이가 존재할 수 있음을 고려하여 실험을 진행**하였다.

위 과정을 다음과 같이 시각화할 수 있다.
```{r, echo=FALSE, fig.align='center', out.width="80%"}
knitr::include_graphics('figure_learning.png')
```

### **6.5 Feature Importance 분석**

각 머신러닝 모델의 **Permutation Feature Importance**와 **SHAP 값(Shapley Additive Explanations, SHAP value)**을 활용하여 변수 중요도를 분석한다.  
* **Permutation Feature Importance**는 테이블 형태로 제시하여 각 변수의 상대적 중요도를 수치적으로 확인한다.  
* **SHAP 값**은 **beeswarm plot**을 사용하여 모델이 특정 예측을 수행하는 과정에서 개별 변수가 미치는 영향을 시각적으로 분석한다.  

모델별 최종 학습 결과 중 **5-fold cross-validation의 테스트 성능이 가장 우수한 폴드(fold)의 결과를 선택하여 분석**을 진행한다.

## **7. 비례위험 가정 검정**

DeepSurv와 TabNet, CoxPH는 **비례위험 가정(Proportional Hazards Assumption)**을 기반으로 한 생존 분석 모델이다.  
반면, **Random Survival Forest(RSF)**는 비례위험 가정을 요구하지 않는다.

따라서, **DeepSurv와 TabNet을 적용하기 전에 비례위험 가정이 충족되는지 검증**하는 과정이 필요하다.  
이를 통해 **모델 사용의 타당성을 높이고, 분석 결과의 신뢰성을 확보**할 수 있다.


### **7.1 비례위험 가정에 대한 통계적 검정**

비례위험 가정을 검정하는 대표적인 방법 중 하나가  
**Schoenfeld 잔차 검정(Schoenfeld Residual Test)**이다.

#### **Schoenfeld 잔차 검정 가설**
* 귀무가설 $H_0$ : **비례위험 가정이 성립**한다.  
* 대립가설 $H_1$ : **비례위험 가정이 성립하지 않는다.**

이 검정에서 사용되는 **검정통계량은 카이제곱(Chi-square) 분포**를 따르며,  
**p-value가 0.05보다 작을 경우** 귀무가설을 기각하고 해당 변수에서 **비례위험 가정이 성립하지 않는다고 판단**한다.

#### **R에서의 Schoenfeld 잔차 검정 수행 방법**

Schoenfeld 잔차 검정은 R의 `survival` 패키지에서 제공하는 `cox.zph()` 함수를 활용한다. `cox.zph()`는 다변량 CoxPH에 포함된 각 변수에 대해 개별적으로 비례위험 가정이 성립하는지 검정하며, 모델 전체의 비례위험 가정에 대한 검정(GLOBAL 검정)도 함께 수행한다.

이러한 검정을 통해 DeepSurv와 TabNet을 사용하기 전에 비례위험 가정이 충족되는지 확인하고, 필요할 경우 시간의존적 효과를 추가하여 모델을 보정하는 과정이 필수적이다.

```{r}

# 다변량 Cox 회귀 분석 (shared frailty 고려X, AIC 기준, 변수 선택 (4.2.1 참고) )
multivariate_model <- coxph(Surv(fu_total_yr, survival) ~
                              Age_group + type_of_disability_Group2 + tooth_loss_reason + 
                              implant_site + prosthesis_type + periodontal_diagnosis_group, data = data)

# Schoenfeld 잔차 검정 수행
NPH_CHECK <- cox.zph(multivariate_model) 
print(NPH_CHECK)
```

검정 수행 결과, 다변량 CoxPH에 포함된 각 변수에 대해 개별적으로 비례위험 가정의 성립 여부를 확인할 수 있었다.
검정 결과, `Age_group` 변수에서는 95% 유의수준에서 비례위험 가정이 성립하지 않는 것으로 나타났다. 또한, GLOBAL 행의 p-value가 작게 나타났으며, 이는 모델 전체적으로 비례위험 가정이 성립하지 않는다는 것을 의미한다.

### **7.2 Schoenfeld 잔차 검정 결과의 시각적 해석**

```{r}
par(mfrow=c(2,3))  # 다중 플롯
plot(NPH_CHECK)    # Schoenfeld 잔차 플롯
```

`cox.zph()`을 활용한 그래프로 비례위험 가정에 대한 시각적인 확인도 가능하다.
`cox.zph()`을 통해 얻은 그래프는 시간에 따른 계수 $\beta(t)$의 변화를 추정한 결과를 나타낸다.
* 만약 비례위험 가정이 성립한다면, $\beta(t)$ 값이 시간에 따라 일정해야 하므로 그래프가 수평선을 이루어야 한다.
* 그래프의 선형 적합(linear fit) 결과는 기울기(slope)$= 0$을 검정하는 공식적인 검정 결과를 근사하는 역할을 한다.
검정 결과를 시각적으로 확인한 결과, 다음과 같은 패턴이 관찰되었다.
* 비례위험 가정을 기각한 `Age_group` 변수의 그래프는 시간이 지남에 따라 우상향하는 패턴을 보였다.
    * 이는 시간이 흐름에 따라 해당 변수의 영향력이 증가하거나 감소한다는 것을 의미하며, 비례위험 가정이 성립하지 않을 가능성이 높음을 시사한다.
* 반면, 검정 결과에서는 비례위험 가정이 성립한다고 판정되었음에도 그래프에서 수평선에서 벗어난 형태를 보이는 경우가 있었다.
* `type_of_disability`와 `implant_site` 변수의 그래프는 시간에 따른 변동이 존재하지만, 전체적으로 볼 때 수평선과 유사한 형태를 보였다.
    * 이는 비례위험 가정 검정이 선형적인 관계만을 가정하기 때문에, 보다 복잡한 시간 의존적 관계(예: 3차 함수 이상의 형태)가 존재할 경우 검정만으로는 완전히 파악할 수 없음을 의미한다.
따라서, 비례위험 가정 검정의 결과만을 맹신해서는 안 되며, Schoenfeld 잔차 그래프를 함께 분석하여 해석하는 것이 필수적이다.


### **7.3 비례위험 가정 위배 변수에 대한 보정 (시간의존적 효과 추가)**

Schoenfeld 잔차 검정을 활용한 결과,  
`Age_group`에서 시간이 지남에 따라 **계수 $\beta_j(t)$ 가 증가**하는 경향을 보였다.
이는 해당 변수들이 시간이 흐름에 따라 위험도에 미치는 영향이 변화한다는 것을 의미한다.

이를 반영하기 위해, 기존 CoxPH 모델을 다음과 같이 수정할 수 있다.

$$
\beta_j(t) = \beta_j + v_j (t - \bar{t})
$$

또는 단순한 형태로

$$
\beta_j(t) = \beta_j \cdot t
$$
와 같이 수정 가능하다.

모델을 적용하면, 시간이 경과함에 따라 특정 독립변수가 위험도에 미치는 영향이 증가하거나 감소하는 패턴을 반영할 수 있다. 예를 들어, $\beta_j > 0$인 경우 $j$번째 변수의 위험 기여도가 시간이 지남에 따라 증가하는 것으로 해석할 수 있다.

#### **시간의존적 효과 변수 추가 방법**

시간의존적 효과 변수를 추가하는 방법은 `Surv()` 함수와 `coxph()` 함수의 `tt()` 옵션을 활용하여 구현할 수 있다.
아래 코드는 `Age_group`에 대해 시간의존적 효과를 반영하는 방식으로 Cox 회귀 모델을 구축한 것이다.

```{r}
# Step 1: 변수 더미화 (Dummy Variable Transformation)
data <- data %>%
  mutate(
    age_under_40 = ifelse(Age_group == "Under 40", 1, 0),
    age_btw_40_59 = ifelse(Age_group == "40-59", 1, 0)
  )

# Step 2: 시간의존적 효과를 포함한 Cox 모델 적합
cox_model_fixed <- coxph(Surv(fu_total_yr, survival) ~ 
                               age_under_40 + age_btw_40_59 + type_of_disability_Group2 + tooth_loss_reason + 
                               implant_site + prosthesis_type + periodontal_diagnosis_group
                           + tt(age_under_40) + tt(age_btw_40_59), 
                         data = data, tt=function(x,t,...) x*t)
```
이 코드에서 tt(variable) 옵션을 추가하여, 해당 변수와 시간(time) 간의 상호작용을 반영하도록 모델을 설정하였다.

**결과 및 해석**
시간의존적 효과를 반영한 Cox 모델을 적합한 결과, Concordance Index (C-index)가 기존 0.75에서 0.789로 증가하였다.(아래 코드 참고) 이는 비례위험 가정 위배 문제를 해결함과 동시에 모델의 유의성이 강화됐음을 뜻한다.
따라서, 비례위험 가정이 위배된 변수를 포함하는 Cox 모델을 적용할 때는 Schoenfeld 잔차 검정을 수행한 후, 필요한 경우 시간의존적 효과 변수를 추가하여 모델의 타당성을 높이는 것이 바람직하다.

```{r}
# Time dependent 변수 추가 전
multivariate_model <- coxph(Surv(fu_total_yr, survival) ~
                              Age_group + type_of_disability_Group2 + tooth_loss_reason + 
                              implant_site + prosthesis_type + periodontal_diagnosis_group, data = data)

summary(multivariate_model)
```

```{r}
# Time dependent 변수 추가 후
cox_model_fixed <- coxph(Surv(fu_total_yr, survival) ~ 
                               age_under_40 + age_btw_40_59 + type_of_disability_Group2 + tooth_loss_reason + 
                               implant_site + prosthesis_type + periodontal_diagnosis_group
                           + tt(age_under_40) + tt(age_btw_40_59), 
                         data = data, tt=function(x,t,...) x*t)

summary(cox_model_fixed)
```

## **8. RSF 학습 결과**

### **8.1 RSF 최적 하이퍼파라미터 값**
```{yaml}
rsf:
 n_estimators: 704
min_samples_leaf: 20
max_features: 11
max_depth: 5
```

### **8.2 5-fold Cross Validation 성능 결과**
각 폴드(fold)에서 평가된 **C-Index, Mean AUC, IBS**는 다음과 같다.

```{r}
results <- data.frame(
  Fold = c(0, 1, 2, 3, 4),
  C_Index = c(0.5553, 0.7281, 0.5400, 0.8207, 0.8813),
  Mean_AUC = c(NA, 0.7263, 0.5859, 0.8680, 0.9061),
  IBS = c(0.0723, 0.0277, 0.0484, 0.0424, 0.0441)
)

print(results)
```

**모델 최종 scores**

|`c_index`|`mean_auc`|`ibs`|
|:-------|:------|:---------|
|0.705071          |0.771574                 |0.046981                 |

### **8.3 Feature Importance**

위의 결과를 이용해 **fold_3**(`c_index`: 0.8206521739130435, `mean_auc`: 0.8679510931739639, `ibs`: 0.04237957274490644)의 feature importance를 분석한다.

```{r}
library(tidyverse)
RSF_permutation_importances_fold_3 <- read_csv("RSF_permutation_importances_fold_3.csv")
print(RSF_permutation_importances_fold_3)
```
`implant_site_p`, `prosthesis_type_single`, `tooth_loss_reason_perio` 순으로 변수 중요도가 높게 측정되었다.
변수 중요도가 0에 가깝거나, 음수가 나오는 변수들도 여럿 존재함을 확인할 수 있다.


```{r}
knitr::include_graphics('RSF_beeswarm_fold_3.png')
```

RSF 모델에선 범주형 변수의 값에 따라 예측값의 영향이 명확하다는 것을 그래프를 통해서도 확인할 수 있다. `implant_site`가 `a`인 관측치들은 risk를 높이는 쪽으로 영향을 줬고, `p`인 관측치들은 risk를 낮추는 쪽으로 영향을 줬다. `prothesis_type`도 예측에 영향을 주는 것을 확인할 수 있다. `prothesis_type`이 `single`일 경우 위험도를 높게 예측한다. Tree-based 모델 특성상 범주형 변수의 값에 따라 예측값이 달라지는 경향이 있다. 그러한 모델의 특성을 SHAP value의 그래프에서도 확인할 수 있다.




## **9. DeepSurv 학습 결과**

### **9.1 RSF 최적 하이퍼파라미터 값**
```{yaml}
rsf:
 batch_size: 1024
  inner_dim: 64
  lr: 1e-05
  weight_decay: 0.01
```

* `config.yaml`에 제시된 `batch_size`는 512, 1024, 1770, 3540이다. 현 데이터의 경우, 행 개수가 약 500개이므로 유의미한 `batch_size`를 찾을 수 없다.

### **9.2 5-fold Cross Validation 성능 결과**
각 폴드(fold)에서 평가된 **C-Index, Mean AUC, IBS**는 다음과 같다.

```{r}
results <- data.frame(
  Fold = c(0, 1, 2, 3, 4),
  C_Index = c(0.5913, 0.5530, 0.4528, 0.6141, 0.3984),
  Mean_AUC = c(NA, 0.5255, 0.3549, 0.5401, 0.4221),
  IBS = c(0.1035, 0.0314, 0.0632, 0.0596, 0.0653)
)

print(results)
```

**모델 최종 scores**

|`c_index`|`mean_auc`|`ibs`|
|:-------|:------|:---------|
|0.521925         | 0.460670                |0.064590                |

### **9.3 Feature Importance**

위의 결과를 이용해 **fold_3**(`c_index`: 0.6141304347826086,  `mean_auc`: 0.5401079712774866,  `ibs`: 0.05955015236923045)의 feature importance를 분석한다.

```{r}
DeepSurv_permutation_importances_fold_3 <- read_csv("DeepSurv_permutation_importances_fold_3.csv")
print(DeepSurv_permutation_importances_fold_3)
```
`jaw_mx`, `Sex_M`, `type_of_disability_Group2_Non-Mental` 순으로 변수 중요도가 높게 측정되었다.
RSF와 마찬가지로, 변수 중요도가 0에 가깝거나, 음수가 나오는 변수들도 여럿 존재함을 확인할 수 있다.


```{r}
knitr::include_graphics('DeepSurv_beeswarm_fold_3.png')
```

(설명)


---

#### 참고문헌

1. **Klein, John P., et al. (2003).** Censoring and truncation. *Survival Analysis: Techniques for Censored and Truncated Data*, 63-90.

2. **Gutierrez, Roberto G. (2002).** Parametric frailty and shared frailty survival models. *The Stata Journal*, 2(1), 22-44.

3. **Harrell, Frank E. (2001).** *Regression Modeling Strategies: With Applications to Linear Models, Logistic Regression, and Survival Analysis.* Springer.

4. **Hung, H., & Chiang, C.-T. (2010).** Estimation methods for time-dependent AUC models with survival data. *Canadian Journal of Statistics*, 38(1), 8–26.

5. **Clark, Taane G., & Altman, Douglas G. (2003).** Developing a prognostic model in the presence of missing data: an ovarian cancer case study. *Journal of Clinical Epidemiology*, 56(1), 28-37.

6. **Germer, Sebastian, et al. (2024).** Survival analysis for lung cancer patients: A comparison of Cox regression and machine learning models. *International Journal of Medical Informatics*, 191, 105607.

7. **Therneau, T. M., & Grambsch, P. M. (2000).** *Modeling Survival Data: Extending the Cox Model.* Springer.

8. **Kleinbaum, D. G., & Klein, M. (2012).** *Survival Analysis: A Self-Learning Text (3rd ed.).* Springer.

9. **Katzman, J.L., Shaham, U., Cloninger, A. et al.** DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network. BMC Med Res Methodol 18, 24 (2018). https://doi.org/10.1186/s12874-018-0482-1

