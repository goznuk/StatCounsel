{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9b5a4b-0e51-48ef-a1d4-be765606297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.util import Surv\n",
    "from sklearn.inspection import permutation_importance\n",
    "import optuna\n",
    "import shap\n",
    "from explainability import SHAP\n",
    "from evaluation import evaluate_survival_model, PartialLogLikelihood\n",
    "from training_survival_analysis import train_model\n",
    "from models import MinimalisticNetwork\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae5a4ac-5158-467c-88a1-18310f642f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rsf_data(df, time_col, event_col, random_state=1234, test_size=0.1, n_splits=5):\n",
    "    \"\"\"\n",
    "    RSF 모델 학습을 위한 데이터 준비 함수.\n",
    "    \n",
    "    Args:\n",
    "        df: 전처리된 데이터프레임 (결측치 없는 상태)\n",
    "        time_col: 생존 시간을 나타내는 컬럼명 (ex: 'fu_total_yr')\n",
    "        event_col: 생존 여부를 나타내는 컬럼명 (ex: 'survival')\n",
    "        random_state: 재현성을 위한 랜덤 시드\n",
    "        test_size: Train / test set split 비율. 0.1 디폴트\n",
    "        n_splits: cross validation fold 수. 5 디폴트\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test, kfold\n",
    "    \"\"\"\n",
    "    # 독립변수(X)에서 time_col, event_col 제거 후 One-Hot Encoding\n",
    "    X = df.drop(columns=[time_col, event_col])\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    # 종속변수(y)를 구조화 배열로 변환\n",
    "    y = np.zeros(df.shape[0], dtype=[('vit_status', '?'), ('survival_time', '<f8')])\n",
    "    y['vit_status'] = df[event_col].values.astype(bool)\n",
    "    y['survival_time'] = df[time_col].values.astype(float)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # 데이터 분할 (Train/Test Split)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # KFold 설정\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, kfold\n",
    "\n",
    "# 함수 과정 : X & y 생성, RSF 학습 위한 One-Hot Encoding, train/test split, fold 정의."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb7200d-0e88-44ca-906d-f162fbd610c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rsf(X_train, y_train, kfold, random_state=1234, n_trials=50):\n",
    "    \"\"\"\n",
    "    Optuna를 사용해 Random Survival Forest의 최적 하이퍼파라미터를 찾는 함수.\n",
    "\n",
    "    Args:\n",
    "        X_train: 훈련 데이터 (독립변수)\n",
    "        y_train: 훈련 데이터 (종속변수)\n",
    "        kfold: K-Fold 객체\n",
    "        random_state: 랜덤 시드\n",
    "        n_trials: Optuna 하이퍼파라미터 서치 횟수\n",
    "\n",
    "    Returns:\n",
    "        best_params: 최적의 하이퍼파라미터\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    # 설정 파일 로드\n",
    "    config = yaml.safe_load(Path(\"./config.yaml\").read_text())\n",
    "    rsf_config = config[\"rsf\"]\n",
    "    selected_features = X_train.columns\n",
    "    rsf_config[\"max_features\"][\"max\"] = len(selected_features)\n",
    "    model_name = \"rsf\"\n",
    "\n",
    "    def objective_rsf(trial: optuna.Trial):\n",
    "        \"\"\"Optuna에서 사용할 목적 함수\"\"\"\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", rsf_config[\"n_estimators\"][\"min\"], rsf_config[\"n_estimators\"][\"max\"]),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", rsf_config[\"min_samples_leaf\"][\"min\"], rsf_config[\"min_samples_leaf\"][\"max\"]),\n",
    "            \"max_features\": trial.suggest_int(\"max_features\", rsf_config[\"max_features\"][\"min\"], rsf_config[\"max_features\"][\"max\"]),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", rsf_config[\"max_depth\"][\"min\"], rsf_config[\"max_depth\"][\"max\"]),\n",
    "        }\n",
    "        scores = []\n",
    "        for train_idx, _ in kfold.split(X_train, y_train):\n",
    "            X_fold = X_train.iloc[train_idx]\n",
    "            model = RandomSurvivalForest(n_estimators=params[\"n_estimators\"],\n",
    "                                        min_samples_leaf=params[\"min_samples_leaf\"],\n",
    "                                        max_features=params[\"max_features\"],\n",
    "                                        max_depth=params[\"max_depth\"],\n",
    "                                        random_state=random_state, n_jobs=-1)\n",
    "            model.fit(X_fold, y_train[train_idx])\n",
    "            score = model.score(X_fold, y_train[train_idx])\n",
    "            scores.append(score)\n",
    "        return np.mean(scores)\n",
    "\n",
    "    # Optuna 실행\n",
    "    study = optuna.create_study(study_name=model_name+str(datetime.datetime.now()),\n",
    "                                direction=\"maximize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=random_state))\n",
    "    study.optimize(objective_rsf, n_trials=n_trials)\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d2e15b-8f2b-4c02-ae24-45899c7b3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_rsf(X_train, X_test, y_train, y_test, best_params, kfold, random_state=1234):\n",
    "    \"\"\"\n",
    "    Random Survival Forest를 학습하고 평가하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test, y_train, y_test: 훈련 및 테스트 데이터\n",
    "        best_params: Optuna에서 찾은 최적 하이퍼파라미터\n",
    "        kfold: K-Fold 객체\n",
    "        random_state: 랜덤 시드\n",
    "    \n",
    "    Returns:\n",
    "        각 fold별 feature importance : .csv 파일로 저장, SHAP values beeswarm plot : .png파일로 저장 \n",
    "        fi: K-Fold 결과 DataFrame\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    # 각 fold의 결과를 저장할 딕셔너리 생성\n",
    "    fold_scores = {}\n",
    "    \n",
    "    # 최종 모델 학습 및 결과 저장\n",
    "    for i, (train_fold, val_fold) in enumerate(kfold.split(X_train, y_train)):\n",
    "        X_train_fold = X_train.iloc[train_fold]\n",
    "        X_val_fold = X_train.iloc[val_fold]\n",
    "        best_model = RandomSurvivalForest(**best_params, random_state=random_state, n_jobs=-1)\n",
    "        best_model.fit(X_train_fold, y_train[train_fold])\n",
    "        \n",
    "        # 평가 결과 저장\n",
    "        scores = evaluate_survival_model(best_model, X_val_fold, y_train[train_fold], y_train[val_fold])\n",
    "        print(f\"Final RSF Scores in Fold {i}: {scores}\")\n",
    "        fold_scores[f\"fold_{i}\"] = scores  \n",
    "    \n",
    "        # ---- Permutation Importance 저장 ----\n",
    "        result = permutation_importance(best_model, X_val_fold, y_train[val_fold], n_repeats=15, random_state=random_state)\n",
    "        result_dict = {k: result[k] for k in (\"importances_mean\", \"importances_std\")}\n",
    "        permutation_importances = pd.DataFrame(result_dict, index=X_val_fold.columns).sort_values(by=\"importances_mean\", ascending=False)\n",
    "    \n",
    "        perm_imp_path = f\"RSF_permutation_importances_fold_{i}.csv\"\n",
    "        permutation_importances.to_csv(perm_imp_path, encoding = 'utf-8')\n",
    "        print(f\"Permutation importances saved to {perm_imp_path}\")\n",
    "        \n",
    "        # ---- SHAP values 저장 ----\n",
    "        explainer = shap.Explainer(best_model.predict, X_val_fold)\n",
    "        shap_values = explainer(X_val_fold)\n",
    "        \n",
    "        # ---- SHAP Beeswarm Plot 저장 ----\n",
    "        plt.figure(figsize=(10, 6))  # 적절한 크기 설정\n",
    "        shap.plots.beeswarm(shap_values, show=False)\n",
    "        \n",
    "        beeswarm_path = f\"RSF_beeswarm_fold_{i}.png\"\n",
    "        plt.tight_layout()  # 여백 자동 조정\n",
    "        plt.savefig(beeswarm_path, dpi=300, bbox_inches=\"tight\")  # 잘림 방지\n",
    "        plt.close()  # 메모리 정리\n",
    "        print(f\"Beeswarm plot saved to {beeswarm_path}\")\n",
    "        \n",
    "    # Final Scores\n",
    "    fold_scores = pd.DataFrame(fold_scores).T\n",
    "    final_scores = fold_scores.mean(skipna=True)\n",
    "    print(final_scores)\n",
    "\n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58da36d3-0b7f-4208-96e6-e40cdd89a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# 전처리 ################\n",
    "\n",
    "df = pd.read_csv(\"processed_survival_data_modified.csv\") # processed_survival_data_modified : Age 범주화한 데이터셋\n",
    "df[\"implant_length_group\"] = df[\"implant_length_group\"].apply(\n",
    "    lambda x: \"Length ≥ 10\" if x == \"길이 10 이상\" else \"Length < 10\"\n",
    ")\n",
    "df[\"survival\"] = df[\"survival\"].map({\"survive\": 0, \"fail\": 1}) # 종속변수(수술 성공 여부)를 0, 1로 변환\n",
    "# 분석 제외할 변수 제거\n",
    "exclude_columns = [\"patient_ID\", \"me\", \"failure_reason\", \"failure_date\", \n",
    "                   \"last_fu_date\", \"surgery_Date\", \"fu_for_fail_yr\", \"fu_for_survival_yr\"]\n",
    "all_columns = [col for col in df.columns if col not in exclude_columns] # 분석에 사용할 변수만 포함\n",
    "# 지정한 컬럼들에 결측치가 있는 행 제거\n",
    "df = df.dropna(subset = all_columns)\n",
    "df = df[all_columns]\n",
    "selected_features = [col for col in df.columns if col not in ['fu_total_yr', 'survival'] + exclude_columns]\n",
    "time_col = \"fu_total_yr\"\n",
    "event_col = \"survival\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9fa6a1-0169-4baa-93d7-0c09cf4deaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-09 11:50:43,580] A new study created in memory with name: rsf2025-03-09 11:50:43.579110\n",
      "[I 2025-03-09 11:50:45,739] Trial 0 finished with value: 0.8655542072431187 and parameters: {'n_estimators': 199, 'min_samples_leaf': 21, 'max_features': 9, 'max_depth': 12}. Best is trial 0 with value: 0.8655542072431187.\n",
      "[I 2025-03-09 11:50:56,914] Trial 1 finished with value: 0.8954734093203219 and parameters: {'n_estimators': 782, 'min_samples_leaf': 12, 'max_features': 6, 'max_depth': 13}. Best is trial 1 with value: 0.8954734093203219.\n",
      "[I 2025-03-09 11:51:10,436] Trial 2 finished with value: 0.841404433219548 and parameters: {'n_estimators': 959, 'min_samples_leaf': 27, 'max_features': 7, 'max_depth': 9}. Best is trial 1 with value: 0.8954734093203219.\n",
      "[I 2025-03-09 11:51:19,805] Trial 3 finished with value: 0.8552077615387697 and parameters: {'n_estimators': 687, 'min_samples_leaf': 23, 'max_features': 7, 'max_depth': 9}. Best is trial 1 with value: 0.8954734093203219.\n",
      "[I 2025-03-09 11:51:26,462] Trial 4 finished with value: 0.9484165109546133 and parameters: {'n_estimators': 508, 'min_samples_leaf': 5, 'max_features': 14, 'max_depth': 14}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:51:31,081] Trial 5 finished with value: 0.8562307386878862 and parameters: {'n_estimators': 371, 'min_samples_leaf': 21, 'max_features': 3, 'max_depth': 7}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:51:44,664] Trial 6 finished with value: 0.8650855218396405 and parameters: {'n_estimators': 934, 'min_samples_leaf': 21, 'max_features': 8, 'max_depth': 13}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:51:48,456] Trial 7 finished with value: 0.8649228493907402 and parameters: {'n_estimators': 323, 'min_samples_leaf': 19, 'max_features': 15, 'max_depth': 8}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:51:59,483] Trial 8 finished with value: 0.9235774220260765 and parameters: {'n_estimators': 804, 'min_samples_leaf': 8, 'max_features': 13, 'max_depth': 11}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:01,992] Trial 9 finished with value: 0.8347500076579404 and parameters: {'n_estimators': 226, 'min_samples_leaf': 29, 'max_features': 9, 'max_depth': 14}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:08,649] Trial 10 finished with value: 0.828811145639422 and parameters: {'n_estimators': 537, 'min_samples_leaf': 5, 'max_features': 17, 'max_depth': 2}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:09,095] Trial 11 finished with value: 0.946241964123266 and parameters: {'n_estimators': 41, 'min_samples_leaf': 5, 'max_features': 13, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:16,146] Trial 12 finished with value: 0.8911116925087651 and parameters: {'n_estimators': 517, 'min_samples_leaf': 13, 'max_features': 13, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:16,509] Trial 13 finished with value: 0.9402596259252171 and parameters: {'n_estimators': 25, 'min_samples_leaf': 5, 'max_features': 12, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:17,469] Trial 14 finished with value: 0.8972129691528998 and parameters: {'n_estimators': 101, 'min_samples_leaf': 11, 'max_features': 11, 'max_depth': 5}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:22,639] Trial 15 finished with value: 0.8790997863667671 and parameters: {'n_estimators': 424, 'min_samples_leaf': 15, 'max_features': 15, 'max_depth': 11}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:30,556] Trial 16 finished with value: 0.9173104869511342 and parameters: {'n_estimators': 611, 'min_samples_leaf': 9, 'max_features': 17, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:33,314] Trial 17 finished with value: 0.9233883130814504 and parameters: {'n_estimators': 243, 'min_samples_leaf': 8, 'max_features': 15, 'max_depth': 11}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:39,068] Trial 18 finished with value: 0.8850327920545528 and parameters: {'n_estimators': 467, 'min_samples_leaf': 15, 'max_features': 11, 'max_depth': 13}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:48,373] Trial 19 finished with value: 0.941482266964919 and parameters: {'n_estimators': 666, 'min_samples_leaf': 5, 'max_features': 14, 'max_depth': 6}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:52:51,961] Trial 20 finished with value: 0.8229867530522608 and parameters: {'n_estimators': 315, 'min_samples_leaf': 9, 'max_features': 11, 'max_depth': 2}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:53:01,187] Trial 21 finished with value: 0.9290385647436625 and parameters: {'n_estimators': 667, 'min_samples_leaf': 5, 'max_features': 14, 'max_depth': 5}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:53:09,034] Trial 22 finished with value: 0.9197893070859247 and parameters: {'n_estimators': 580, 'min_samples_leaf': 7, 'max_features': 13, 'max_depth': 5}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:53:19,875] Trial 23 finished with value: 0.902553695312872 and parameters: {'n_estimators': 781, 'min_samples_leaf': 11, 'max_features': 16, 'max_depth': 7}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:53:28,494] Trial 24 finished with value: 0.9291940300536699 and parameters: {'n_estimators': 646, 'min_samples_leaf': 7, 'max_features': 14, 'max_depth': 6}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:53:40,315] Trial 25 finished with value: 0.8681681410953672 and parameters: {'n_estimators': 867, 'min_samples_leaf': 5, 'max_features': 12, 'max_depth': 3}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:53:50,151] Trial 26 finished with value: 0.909054210639449 and parameters: {'n_estimators': 725, 'min_samples_leaf': 10, 'max_features': 16, 'max_depth': 10}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:53:55,555] Trial 27 finished with value: 0.8880030793657792 and parameters: {'n_estimators': 433, 'min_samples_leaf': 14, 'max_features': 10, 'max_depth': 14}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:02,932] Trial 28 finished with value: 0.8634994545369666 and parameters: {'n_estimators': 572, 'min_samples_leaf': 17, 'max_features': 2, 'max_depth': 14}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:03,296] Trial 29 finished with value: 0.9252156503056573 and parameters: {'n_estimators': 25, 'min_samples_leaf': 7, 'max_features': 14, 'max_depth': 12}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:05,100] Trial 30 finished with value: 0.9393288771091293 and parameters: {'n_estimators': 163, 'min_samples_leaf': 6, 'max_features': 12, 'max_depth': 12}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:05,558] Trial 31 finished with value: 0.9443681277120598 and parameters: {'n_estimators': 41, 'min_samples_leaf': 5, 'max_features': 12, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:06,967] Trial 32 finished with value: 0.9174271009779821 and parameters: {'n_estimators': 139, 'min_samples_leaf': 9, 'max_features': 10, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:07,840] Trial 33 finished with value: 0.930490323079818 and parameters: {'n_estimators': 88, 'min_samples_leaf': 7, 'max_features': 13, 'max_depth': 14}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:10,816] Trial 34 finished with value: 0.8976477695974285 and parameters: {'n_estimators': 282, 'min_samples_leaf': 12, 'max_features': 5, 'max_depth': 13}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:11,736] Trial 35 finished with value: 0.8455022946042039 and parameters: {'n_estimators': 79, 'min_samples_leaf': 26, 'max_features': 16, 'max_depth': 4}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:13,641] Trial 36 finished with value: 0.9394730954767132 and parameters: {'n_estimators': 183, 'min_samples_leaf': 6, 'max_features': 14, 'max_depth': 8}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:18,425] Trial 37 finished with value: 0.9100378006408899 and parameters: {'n_estimators': 395, 'min_samples_leaf': 10, 'max_features': 8, 'max_depth': 12}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:28,813] Trial 38 finished with value: 0.9398495197068005 and parameters: {'n_estimators': 757, 'min_samples_leaf': 6, 'max_features': 12, 'max_depth': 10}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:43,263] Trial 39 finished with value: 0.9234899814094477 and parameters: {'n_estimators': 994, 'min_samples_leaf': 8, 'max_features': 15, 'max_depth': 7}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:49,155] Trial 40 finished with value: 0.8525845830393692 and parameters: {'n_estimators': 475, 'min_samples_leaf': 25, 'max_features': 9, 'max_depth': 14}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:49,497] Trial 41 finished with value: 0.9374906113417861 and parameters: {'n_estimators': 16, 'min_samples_leaf': 5, 'max_features': 12, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:50,167] Trial 42 finished with value: 0.9464178338504203 and parameters: {'n_estimators': 66, 'min_samples_leaf': 5, 'max_features': 13, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:51,326] Trial 43 finished with value: 0.9386494723779908 and parameters: {'n_estimators': 122, 'min_samples_leaf': 6, 'max_features': 13, 'max_depth': 13}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:51,872] Trial 44 finished with value: 0.8195414722688268 and parameters: {'n_estimators': 54, 'min_samples_leaf': 30, 'max_features': 14, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:54,237] Trial 45 finished with value: 0.9219562181525534 and parameters: {'n_estimators': 217, 'min_samples_leaf': 8, 'max_features': 11, 'max_depth': 14}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:54:58,639] Trial 46 finished with value: 0.8577824769453306 and parameters: {'n_estimators': 370, 'min_samples_leaf': 22, 'max_features': 13, 'max_depth': 15}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:55:01,659] Trial 47 finished with value: 0.9467022583077004 and parameters: {'n_estimators': 265, 'min_samples_leaf': 5, 'max_features': 15, 'max_depth': 9}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:55:05,180] Trial 48 finished with value: 0.8647846890674391 and parameters: {'n_estimators': 282, 'min_samples_leaf': 19, 'max_features': 16, 'max_depth': 13}. Best is trial 4 with value: 0.9484165109546133.\n",
      "[I 2025-03-09 11:55:06,664] Trial 49 finished with value: 0.9101503631065985 and parameters: {'n_estimators': 150, 'min_samples_leaf': 10, 'max_features': 17, 'max_depth': 10}. Best is trial 4 with value: 0.9484165109546133.\n",
      "/home/kjh1017/.local/lib/python3.10/site-packages/sksurv/metrics.py:483: RuntimeWarning: invalid value encountered in divide\n",
      "  true_pos = cumsum_tp / cumsum_tp[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RSF Scores in Fold 0: {'c_index': 0.5951156812339332, 'mean_auc': nan, 'ibs': 0.06651475310367631}\n",
      "Permutation importances saved to RSF_permutation_importances_fold_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 99it [04:43,  2.92s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeswarm plot saved to RSF_beeswarm_fold_0.png\n",
      "Final RSF Scores in Fold 1: {'c_index': 0.7050691244239631, 'mean_auc': 0.7196028308103923, 'ibs': 0.025553780533007896}\n",
      "Permutation importances saved to RSF_permutation_importances_fold_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 99it [04:38,  2.93s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeswarm plot saved to RSF_beeswarm_fold_1.png\n",
      "Final RSF Scores in Fold 2: {'c_index': 0.6112099644128114, 'mean_auc': 0.6663719885597116, 'ibs': 0.050266213564786104}\n",
      "Permutation importances saved to RSF_permutation_importances_fold_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 99it [04:42,  2.97s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeswarm plot saved to RSF_beeswarm_fold_2.png\n",
      "Final RSF Scores in Fold 3: {'c_index': 0.7807971014492754, 'mean_auc': 0.8382614629947835, 'ibs': 0.03977933639701428}\n",
      "Permutation importances saved to RSF_permutation_importances_fold_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 98it [04:36,  2.94s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeswarm plot saved to RSF_beeswarm_fold_3.png\n",
      "Final RSF Scores in Fold 4: {'c_index': 0.9134808853118712, 'mean_auc': 0.9445427988183446, 'ibs': 0.039819320678563246}\n",
      "Permutation importances saved to RSF_permutation_importances_fold_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 98it [04:37,  2.95s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeswarm plot saved to RSF_beeswarm_fold_4.png\n",
      "c_index     0.721135\n",
      "mean_auc    0.792195\n",
      "ibs         0.044387\n",
      "dtype: float64\n",
      "c_index     0.721135\n",
      "mean_auc    0.792195\n",
      "ibs         0.044387\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "########## 최종 실행 코드 #############\n",
    "X_train, X_test, y_train, y_test, kfold = prepare_rsf_data(df, \"fu_total_yr\", \"survival\")\n",
    "best_params = optimize_rsf(X_train, y_train, kfold)\n",
    "fold_scores_df = train_and_evaluate_rsf(X_train, X_test, y_train, y_test, best_params, kfold)\n",
    "print(fold_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1f5cf-fa83-47cf-ad46-c7399f7a2804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
